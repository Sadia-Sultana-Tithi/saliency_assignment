{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64c50bdf-8b60-4030-b938-c934e5ed7d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Unisal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e2014e1-5856-41d3-81cb-23aae9938644",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'unisal'...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/rdroste/unisal.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "870f30d1-9fe7-453d-ae2c-2f3106eff244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Downloads\\unisal\n"
     ]
    }
   ],
   "source": [
    "%cd unisal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42ae8e38-bee9-43bf-bf7b-ad94527a608a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\User\\Downloads\\unisal\")  # Add to Python path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6240814-2c3b-4304-98bb-dbb2f662f892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.git', '.gitignore', 'environment.yml', 'examples', 'figures', 'LICENSE', 'README.md', 'run.py', 'training_runs', 'unisal']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir(r\"C:\\Users\\User\\Downloads\\unisal\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8220cef-c113-43da-bc37-56c06d1e8ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cache', 'data.py', 'dhf1k_n_images.dat', 'model.py', 'models', 'salience_metrics.py', 'train.py', 'utils.py', '__init__.py']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(r\"C:\\Users\\User\\Downloads\\unisal\\unisal\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50eb00b8-0314-448a-9be0-a600de22d860",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from unisal.model import Model\n",
    "#from unisal.data import load_datasets\n",
    "#from unisal.utils import visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cf80284-d2c2-4aa0-9fe2-a0bad7570be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboardX in c:\\users\\user\\anaconda3\\lib\\site-packages (2.6.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboardX) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboardX) (24.1)\n",
      "Requirement already satisfied: protobuf>=3.20 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboardX) (4.25.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0e3b1c9-c7fc-4a33-9311-d45f6dea0034",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unisal.model import UNISAL, BaseModel, DomainBatchNorm2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "535b3107-defb-4fe6-9da3-39c8105b348f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unisal import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "077e2336-1c23-43db-b575-b199daaab58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\torch\\functional.py:539: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3638.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully loaded and set to evaluation mode.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Set device (CPU or GPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize the model\n",
    "model = UNISAL().to(device)  # Ensure the constructor is correct\n",
    "\n",
    "# Load the pre-trained model checkpoint\n",
    "model_path = \"C:/Users/User/Downloads/unisal/training_runs/pretrained_unisal/weights_ft_mit1003.pth\"  # Update with actual path\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "\n",
    "# Check if the checkpoint has 'model' or 'state_dict' key\n",
    "if 'model' in checkpoint:\n",
    "    checkpoint = checkpoint['model']  # Extract model weights if needed\n",
    "\n",
    "# Load weights into the model\n",
    "model.load_state_dict(checkpoint)  # Load the checkpoint correctly\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "print(\"Model successfully loaded and set to evaluation mode.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7473ba5-2e1c-4b8d-92a6-44c4141b308b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from scipy.special import logsumexp\n",
    "from tqdm import tqdm\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "939f5461-9776-471c-bbcf-9c47b0605e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = transform(image).unsqueeze(0).to(DEVICE)  # Add batch dimension\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7352d506-99b0-47b6-ae77-b15f1c449ed6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['coarse_gaussians_dhf1k', 'coarse_gaussians_hollywood', 'coarse_gaussians_ucfsports', 'coarse_gaussians_salicon', 'cnn.features.0.0.weight', 'cnn.features.0.1.weight', 'cnn.features.0.1.bias', 'cnn.features.0.1.running_mean', 'cnn.features.0.1.running_var', 'cnn.features.0.1.num_batches_tracked', 'cnn.features.1.conv.0.weight', 'cnn.features.1.conv.1.weight', 'cnn.features.1.conv.1.bias', 'cnn.features.1.conv.1.running_mean', 'cnn.features.1.conv.1.running_var', 'cnn.features.1.conv.1.num_batches_tracked', 'cnn.features.1.conv.3.weight', 'cnn.features.1.conv.4.weight', 'cnn.features.1.conv.4.bias', 'cnn.features.1.conv.4.running_mean', 'cnn.features.1.conv.4.running_var', 'cnn.features.1.conv.4.num_batches_tracked', 'cnn.features.2.conv.0.weight', 'cnn.features.2.conv.1.weight', 'cnn.features.2.conv.1.bias', 'cnn.features.2.conv.1.running_mean', 'cnn.features.2.conv.1.running_var', 'cnn.features.2.conv.1.num_batches_tracked', 'cnn.features.2.conv.3.weight', 'cnn.features.2.conv.4.weight', 'cnn.features.2.conv.4.bias', 'cnn.features.2.conv.4.running_mean', 'cnn.features.2.conv.4.running_var', 'cnn.features.2.conv.4.num_batches_tracked', 'cnn.features.2.conv.6.weight', 'cnn.features.2.conv.7.weight', 'cnn.features.2.conv.7.bias', 'cnn.features.2.conv.7.running_mean', 'cnn.features.2.conv.7.running_var', 'cnn.features.2.conv.7.num_batches_tracked', 'cnn.features.3.conv.0.weight', 'cnn.features.3.conv.1.weight', 'cnn.features.3.conv.1.bias', 'cnn.features.3.conv.1.running_mean', 'cnn.features.3.conv.1.running_var', 'cnn.features.3.conv.1.num_batches_tracked', 'cnn.features.3.conv.3.weight', 'cnn.features.3.conv.4.weight', 'cnn.features.3.conv.4.bias', 'cnn.features.3.conv.4.running_mean', 'cnn.features.3.conv.4.running_var', 'cnn.features.3.conv.4.num_batches_tracked', 'cnn.features.3.conv.6.weight', 'cnn.features.3.conv.7.weight', 'cnn.features.3.conv.7.bias', 'cnn.features.3.conv.7.running_mean', 'cnn.features.3.conv.7.running_var', 'cnn.features.3.conv.7.num_batches_tracked', 'cnn.features.4.conv.0.weight', 'cnn.features.4.conv.1.weight', 'cnn.features.4.conv.1.bias', 'cnn.features.4.conv.1.running_mean', 'cnn.features.4.conv.1.running_var', 'cnn.features.4.conv.1.num_batches_tracked', 'cnn.features.4.conv.3.weight', 'cnn.features.4.conv.4.weight', 'cnn.features.4.conv.4.bias', 'cnn.features.4.conv.4.running_mean', 'cnn.features.4.conv.4.running_var', 'cnn.features.4.conv.4.num_batches_tracked', 'cnn.features.4.conv.6.weight', 'cnn.features.4.conv.7.weight', 'cnn.features.4.conv.7.bias', 'cnn.features.4.conv.7.running_mean', 'cnn.features.4.conv.7.running_var', 'cnn.features.4.conv.7.num_batches_tracked', 'cnn.features.5.conv.0.weight', 'cnn.features.5.conv.1.weight', 'cnn.features.5.conv.1.bias', 'cnn.features.5.conv.1.running_mean', 'cnn.features.5.conv.1.running_var', 'cnn.features.5.conv.1.num_batches_tracked', 'cnn.features.5.conv.3.weight', 'cnn.features.5.conv.4.weight', 'cnn.features.5.conv.4.bias', 'cnn.features.5.conv.4.running_mean', 'cnn.features.5.conv.4.running_var', 'cnn.features.5.conv.4.num_batches_tracked', 'cnn.features.5.conv.6.weight', 'cnn.features.5.conv.7.weight', 'cnn.features.5.conv.7.bias', 'cnn.features.5.conv.7.running_mean', 'cnn.features.5.conv.7.running_var', 'cnn.features.5.conv.7.num_batches_tracked', 'cnn.features.6.conv.0.weight', 'cnn.features.6.conv.1.weight', 'cnn.features.6.conv.1.bias', 'cnn.features.6.conv.1.running_mean', 'cnn.features.6.conv.1.running_var', 'cnn.features.6.conv.1.num_batches_tracked', 'cnn.features.6.conv.3.weight', 'cnn.features.6.conv.4.weight', 'cnn.features.6.conv.4.bias', 'cnn.features.6.conv.4.running_mean', 'cnn.features.6.conv.4.running_var', 'cnn.features.6.conv.4.num_batches_tracked', 'cnn.features.6.conv.6.weight', 'cnn.features.6.conv.7.weight', 'cnn.features.6.conv.7.bias', 'cnn.features.6.conv.7.running_mean', 'cnn.features.6.conv.7.running_var', 'cnn.features.6.conv.7.num_batches_tracked', 'cnn.features.7.conv.0.weight', 'cnn.features.7.conv.1.weight', 'cnn.features.7.conv.1.bias', 'cnn.features.7.conv.1.running_mean', 'cnn.features.7.conv.1.running_var', 'cnn.features.7.conv.1.num_batches_tracked', 'cnn.features.7.conv.3.weight', 'cnn.features.7.conv.4.weight', 'cnn.features.7.conv.4.bias', 'cnn.features.7.conv.4.running_mean', 'cnn.features.7.conv.4.running_var', 'cnn.features.7.conv.4.num_batches_tracked', 'cnn.features.7.conv.6.weight', 'cnn.features.7.conv.7.weight', 'cnn.features.7.conv.7.bias', 'cnn.features.7.conv.7.running_mean', 'cnn.features.7.conv.7.running_var', 'cnn.features.7.conv.7.num_batches_tracked', 'cnn.features.8.conv.0.weight', 'cnn.features.8.conv.1.weight', 'cnn.features.8.conv.1.bias', 'cnn.features.8.conv.1.running_mean', 'cnn.features.8.conv.1.running_var', 'cnn.features.8.conv.1.num_batches_tracked', 'cnn.features.8.conv.3.weight', 'cnn.features.8.conv.4.weight', 'cnn.features.8.conv.4.bias', 'cnn.features.8.conv.4.running_mean', 'cnn.features.8.conv.4.running_var', 'cnn.features.8.conv.4.num_batches_tracked', 'cnn.features.8.conv.6.weight', 'cnn.features.8.conv.7.weight', 'cnn.features.8.conv.7.bias', 'cnn.features.8.conv.7.running_mean', 'cnn.features.8.conv.7.running_var', 'cnn.features.8.conv.7.num_batches_tracked', 'cnn.features.9.conv.0.weight', 'cnn.features.9.conv.1.weight', 'cnn.features.9.conv.1.bias', 'cnn.features.9.conv.1.running_mean', 'cnn.features.9.conv.1.running_var', 'cnn.features.9.conv.1.num_batches_tracked', 'cnn.features.9.conv.3.weight', 'cnn.features.9.conv.4.weight', 'cnn.features.9.conv.4.bias', 'cnn.features.9.conv.4.running_mean', 'cnn.features.9.conv.4.running_var', 'cnn.features.9.conv.4.num_batches_tracked', 'cnn.features.9.conv.6.weight', 'cnn.features.9.conv.7.weight', 'cnn.features.9.conv.7.bias', 'cnn.features.9.conv.7.running_mean', 'cnn.features.9.conv.7.running_var', 'cnn.features.9.conv.7.num_batches_tracked', 'cnn.features.10.conv.0.weight', 'cnn.features.10.conv.1.weight', 'cnn.features.10.conv.1.bias', 'cnn.features.10.conv.1.running_mean', 'cnn.features.10.conv.1.running_var', 'cnn.features.10.conv.1.num_batches_tracked', 'cnn.features.10.conv.3.weight', 'cnn.features.10.conv.4.weight', 'cnn.features.10.conv.4.bias', 'cnn.features.10.conv.4.running_mean', 'cnn.features.10.conv.4.running_var', 'cnn.features.10.conv.4.num_batches_tracked', 'cnn.features.10.conv.6.weight', 'cnn.features.10.conv.7.weight', 'cnn.features.10.conv.7.bias', 'cnn.features.10.conv.7.running_mean', 'cnn.features.10.conv.7.running_var', 'cnn.features.10.conv.7.num_batches_tracked', 'cnn.features.11.conv.0.weight', 'cnn.features.11.conv.1.weight', 'cnn.features.11.conv.1.bias', 'cnn.features.11.conv.1.running_mean', 'cnn.features.11.conv.1.running_var', 'cnn.features.11.conv.1.num_batches_tracked', 'cnn.features.11.conv.3.weight', 'cnn.features.11.conv.4.weight', 'cnn.features.11.conv.4.bias', 'cnn.features.11.conv.4.running_mean', 'cnn.features.11.conv.4.running_var', 'cnn.features.11.conv.4.num_batches_tracked', 'cnn.features.11.conv.6.weight', 'cnn.features.11.conv.7.weight', 'cnn.features.11.conv.7.bias', 'cnn.features.11.conv.7.running_mean', 'cnn.features.11.conv.7.running_var', 'cnn.features.11.conv.7.num_batches_tracked', 'cnn.features.12.conv.0.weight', 'cnn.features.12.conv.1.weight', 'cnn.features.12.conv.1.bias', 'cnn.features.12.conv.1.running_mean', 'cnn.features.12.conv.1.running_var', 'cnn.features.12.conv.1.num_batches_tracked', 'cnn.features.12.conv.3.weight', 'cnn.features.12.conv.4.weight', 'cnn.features.12.conv.4.bias', 'cnn.features.12.conv.4.running_mean', 'cnn.features.12.conv.4.running_var', 'cnn.features.12.conv.4.num_batches_tracked', 'cnn.features.12.conv.6.weight', 'cnn.features.12.conv.7.weight', 'cnn.features.12.conv.7.bias', 'cnn.features.12.conv.7.running_mean', 'cnn.features.12.conv.7.running_var', 'cnn.features.12.conv.7.num_batches_tracked', 'cnn.features.13.conv.0.weight', 'cnn.features.13.conv.1.weight', 'cnn.features.13.conv.1.bias', 'cnn.features.13.conv.1.running_mean', 'cnn.features.13.conv.1.running_var', 'cnn.features.13.conv.1.num_batches_tracked', 'cnn.features.13.conv.3.weight', 'cnn.features.13.conv.4.weight', 'cnn.features.13.conv.4.bias', 'cnn.features.13.conv.4.running_mean', 'cnn.features.13.conv.4.running_var', 'cnn.features.13.conv.4.num_batches_tracked', 'cnn.features.13.conv.6.weight', 'cnn.features.13.conv.7.weight', 'cnn.features.13.conv.7.bias', 'cnn.features.13.conv.7.running_mean', 'cnn.features.13.conv.7.running_var', 'cnn.features.13.conv.7.num_batches_tracked', 'cnn.features.14.conv.0.weight', 'cnn.features.14.conv.1.weight', 'cnn.features.14.conv.1.bias', 'cnn.features.14.conv.1.running_mean', 'cnn.features.14.conv.1.running_var', 'cnn.features.14.conv.1.num_batches_tracked', 'cnn.features.14.conv.3.weight', 'cnn.features.14.conv.4.weight', 'cnn.features.14.conv.4.bias', 'cnn.features.14.conv.4.running_mean', 'cnn.features.14.conv.4.running_var', 'cnn.features.14.conv.4.num_batches_tracked', 'cnn.features.14.conv.6.weight', 'cnn.features.14.conv.7.weight', 'cnn.features.14.conv.7.bias', 'cnn.features.14.conv.7.running_mean', 'cnn.features.14.conv.7.running_var', 'cnn.features.14.conv.7.num_batches_tracked', 'cnn.features.15.conv.0.weight', 'cnn.features.15.conv.1.weight', 'cnn.features.15.conv.1.bias', 'cnn.features.15.conv.1.running_mean', 'cnn.features.15.conv.1.running_var', 'cnn.features.15.conv.1.num_batches_tracked', 'cnn.features.15.conv.3.weight', 'cnn.features.15.conv.4.weight', 'cnn.features.15.conv.4.bias', 'cnn.features.15.conv.4.running_mean', 'cnn.features.15.conv.4.running_var', 'cnn.features.15.conv.4.num_batches_tracked', 'cnn.features.15.conv.6.weight', 'cnn.features.15.conv.7.weight', 'cnn.features.15.conv.7.bias', 'cnn.features.15.conv.7.running_mean', 'cnn.features.15.conv.7.running_var', 'cnn.features.15.conv.7.num_batches_tracked', 'cnn.features.16.conv.0.weight', 'cnn.features.16.conv.1.weight', 'cnn.features.16.conv.1.bias', 'cnn.features.16.conv.1.running_mean', 'cnn.features.16.conv.1.running_var', 'cnn.features.16.conv.1.num_batches_tracked', 'cnn.features.16.conv.3.weight', 'cnn.features.16.conv.4.weight', 'cnn.features.16.conv.4.bias', 'cnn.features.16.conv.4.running_mean', 'cnn.features.16.conv.4.running_var', 'cnn.features.16.conv.4.num_batches_tracked', 'cnn.features.16.conv.6.weight', 'cnn.features.16.conv.7.weight', 'cnn.features.16.conv.7.bias', 'cnn.features.16.conv.7.running_mean', 'cnn.features.16.conv.7.running_var', 'cnn.features.16.conv.7.num_batches_tracked', 'cnn.features.17.conv.0.weight', 'cnn.features.17.conv.1.weight', 'cnn.features.17.conv.1.bias', 'cnn.features.17.conv.1.running_mean', 'cnn.features.17.conv.1.running_var', 'cnn.features.17.conv.1.num_batches_tracked', 'cnn.features.17.conv.3.weight', 'cnn.features.17.conv.4.weight', 'cnn.features.17.conv.4.bias', 'cnn.features.17.conv.4.running_mean', 'cnn.features.17.conv.4.running_var', 'cnn.features.17.conv.4.num_batches_tracked', 'cnn.features.17.conv.6.weight', 'cnn.features.17.conv.7.weight', 'cnn.features.17.conv.7.bias', 'cnn.features.17.conv.7.running_mean', 'cnn.features.17.conv.7.running_var', 'cnn.features.17.conv.7.num_batches_tracked', 'cnn.features.18.0.weight', 'cnn.features.18.1.weight', 'cnn.features.18.1.bias', 'cnn.features.18.1.running_mean', 'cnn.features.18.1.running_var', 'cnn.features.18.1.num_batches_tracked', 'post_cnn.inv_res.conv.0.weight', 'post_cnn.inv_res.conv.1.weight', 'post_cnn.inv_res.conv.1.bias', 'post_cnn.inv_res.conv.1.running_mean', 'post_cnn.inv_res.conv.1.running_var', 'post_cnn.inv_res.conv.1.num_batches_tracked', 'post_cnn.inv_res.conv.3.weight', 'post_cnn.inv_res.conv.4.weight', 'post_cnn.inv_res.conv.4.bias', 'post_cnn.inv_res.conv.4.running_mean', 'post_cnn.inv_res.conv.4.running_var', 'post_cnn.inv_res.conv.4.num_batches_tracked', 'rnn.cell_list.0.b_r', 'rnn.cell_list.0.b_z', 'rnn.cell_list.0.b_h', 'rnn.cell_list.0.a_r_x', 'rnn.cell_list.0.a_r_h', 'rnn.cell_list.0.a_z_x', 'rnn.cell_list.0.a_z_h', 'rnn.cell_list.0.a_h_x', 'rnn.cell_list.0.a_h_h', 'rnn.cell_list.0.drop_mask_1', 'rnn.cell_list.0.norm_r_x.bn_DHF1K.weight', 'rnn.cell_list.0.norm_r_x.bn_DHF1K.bias', 'rnn.cell_list.0.norm_r_x.bn_DHF1K.running_mean', 'rnn.cell_list.0.norm_r_x.bn_DHF1K.running_var', 'rnn.cell_list.0.norm_r_x.bn_DHF1K.num_batches_tracked', 'rnn.cell_list.0.norm_r_x.bn_Hollywood.weight', 'rnn.cell_list.0.norm_r_x.bn_Hollywood.bias', 'rnn.cell_list.0.norm_r_x.bn_Hollywood.running_mean', 'rnn.cell_list.0.norm_r_x.bn_Hollywood.running_var', 'rnn.cell_list.0.norm_r_x.bn_Hollywood.num_batches_tracked', 'rnn.cell_list.0.norm_r_x.bn_UCFSports.weight', 'rnn.cell_list.0.norm_r_x.bn_UCFSports.bias', 'rnn.cell_list.0.norm_r_x.bn_UCFSports.running_mean', 'rnn.cell_list.0.norm_r_x.bn_UCFSports.running_var', 'rnn.cell_list.0.norm_r_x.bn_UCFSports.num_batches_tracked', 'rnn.cell_list.0.norm_r_x.bn_SALICON.weight', 'rnn.cell_list.0.norm_r_x.bn_SALICON.bias', 'rnn.cell_list.0.norm_r_x.bn_SALICON.running_mean', 'rnn.cell_list.0.norm_r_x.bn_SALICON.running_var', 'rnn.cell_list.0.norm_r_x.bn_SALICON.num_batches_tracked', 'rnn.cell_list.0.norm_r_h.bn_DHF1K.weight', 'rnn.cell_list.0.norm_r_h.bn_DHF1K.bias', 'rnn.cell_list.0.norm_r_h.bn_DHF1K.running_mean', 'rnn.cell_list.0.norm_r_h.bn_DHF1K.running_var', 'rnn.cell_list.0.norm_r_h.bn_DHF1K.num_batches_tracked', 'rnn.cell_list.0.norm_r_h.bn_Hollywood.weight', 'rnn.cell_list.0.norm_r_h.bn_Hollywood.bias', 'rnn.cell_list.0.norm_r_h.bn_Hollywood.running_mean', 'rnn.cell_list.0.norm_r_h.bn_Hollywood.running_var', 'rnn.cell_list.0.norm_r_h.bn_Hollywood.num_batches_tracked', 'rnn.cell_list.0.norm_r_h.bn_UCFSports.weight', 'rnn.cell_list.0.norm_r_h.bn_UCFSports.bias', 'rnn.cell_list.0.norm_r_h.bn_UCFSports.running_mean', 'rnn.cell_list.0.norm_r_h.bn_UCFSports.running_var', 'rnn.cell_list.0.norm_r_h.bn_UCFSports.num_batches_tracked', 'rnn.cell_list.0.norm_r_h.bn_SALICON.weight', 'rnn.cell_list.0.norm_r_h.bn_SALICON.bias', 'rnn.cell_list.0.norm_r_h.bn_SALICON.running_mean', 'rnn.cell_list.0.norm_r_h.bn_SALICON.running_var', 'rnn.cell_list.0.norm_r_h.bn_SALICON.num_batches_tracked', 'rnn.cell_list.0.norm_z_x.bn_DHF1K.weight', 'rnn.cell_list.0.norm_z_x.bn_DHF1K.bias', 'rnn.cell_list.0.norm_z_x.bn_DHF1K.running_mean', 'rnn.cell_list.0.norm_z_x.bn_DHF1K.running_var', 'rnn.cell_list.0.norm_z_x.bn_DHF1K.num_batches_tracked', 'rnn.cell_list.0.norm_z_x.bn_Hollywood.weight', 'rnn.cell_list.0.norm_z_x.bn_Hollywood.bias', 'rnn.cell_list.0.norm_z_x.bn_Hollywood.running_mean', 'rnn.cell_list.0.norm_z_x.bn_Hollywood.running_var', 'rnn.cell_list.0.norm_z_x.bn_Hollywood.num_batches_tracked', 'rnn.cell_list.0.norm_z_x.bn_UCFSports.weight', 'rnn.cell_list.0.norm_z_x.bn_UCFSports.bias', 'rnn.cell_list.0.norm_z_x.bn_UCFSports.running_mean', 'rnn.cell_list.0.norm_z_x.bn_UCFSports.running_var', 'rnn.cell_list.0.norm_z_x.bn_UCFSports.num_batches_tracked', 'rnn.cell_list.0.norm_z_x.bn_SALICON.weight', 'rnn.cell_list.0.norm_z_x.bn_SALICON.bias', 'rnn.cell_list.0.norm_z_x.bn_SALICON.running_mean', 'rnn.cell_list.0.norm_z_x.bn_SALICON.running_var', 'rnn.cell_list.0.norm_z_x.bn_SALICON.num_batches_tracked', 'rnn.cell_list.0.norm_z_h.bn_DHF1K.weight', 'rnn.cell_list.0.norm_z_h.bn_DHF1K.bias', 'rnn.cell_list.0.norm_z_h.bn_DHF1K.running_mean', 'rnn.cell_list.0.norm_z_h.bn_DHF1K.running_var', 'rnn.cell_list.0.norm_z_h.bn_DHF1K.num_batches_tracked', 'rnn.cell_list.0.norm_z_h.bn_Hollywood.weight', 'rnn.cell_list.0.norm_z_h.bn_Hollywood.bias', 'rnn.cell_list.0.norm_z_h.bn_Hollywood.running_mean', 'rnn.cell_list.0.norm_z_h.bn_Hollywood.running_var', 'rnn.cell_list.0.norm_z_h.bn_Hollywood.num_batches_tracked', 'rnn.cell_list.0.norm_z_h.bn_UCFSports.weight', 'rnn.cell_list.0.norm_z_h.bn_UCFSports.bias', 'rnn.cell_list.0.norm_z_h.bn_UCFSports.running_mean', 'rnn.cell_list.0.norm_z_h.bn_UCFSports.running_var', 'rnn.cell_list.0.norm_z_h.bn_UCFSports.num_batches_tracked', 'rnn.cell_list.0.norm_z_h.bn_SALICON.weight', 'rnn.cell_list.0.norm_z_h.bn_SALICON.bias', 'rnn.cell_list.0.norm_z_h.bn_SALICON.running_mean', 'rnn.cell_list.0.norm_z_h.bn_SALICON.running_var', 'rnn.cell_list.0.norm_z_h.bn_SALICON.num_batches_tracked', 'rnn.cell_list.0.norm_out_x.bn_DHF1K.weight', 'rnn.cell_list.0.norm_out_x.bn_DHF1K.bias', 'rnn.cell_list.0.norm_out_x.bn_DHF1K.running_mean', 'rnn.cell_list.0.norm_out_x.bn_DHF1K.running_var', 'rnn.cell_list.0.norm_out_x.bn_DHF1K.num_batches_tracked', 'rnn.cell_list.0.norm_out_x.bn_Hollywood.weight', 'rnn.cell_list.0.norm_out_x.bn_Hollywood.bias', 'rnn.cell_list.0.norm_out_x.bn_Hollywood.running_mean', 'rnn.cell_list.0.norm_out_x.bn_Hollywood.running_var', 'rnn.cell_list.0.norm_out_x.bn_Hollywood.num_batches_tracked', 'rnn.cell_list.0.norm_out_x.bn_UCFSports.weight', 'rnn.cell_list.0.norm_out_x.bn_UCFSports.bias', 'rnn.cell_list.0.norm_out_x.bn_UCFSports.running_mean', 'rnn.cell_list.0.norm_out_x.bn_UCFSports.running_var', 'rnn.cell_list.0.norm_out_x.bn_UCFSports.num_batches_tracked', 'rnn.cell_list.0.norm_out_x.bn_SALICON.weight', 'rnn.cell_list.0.norm_out_x.bn_SALICON.bias', 'rnn.cell_list.0.norm_out_x.bn_SALICON.running_mean', 'rnn.cell_list.0.norm_out_x.bn_SALICON.running_var', 'rnn.cell_list.0.norm_out_x.bn_SALICON.num_batches_tracked', 'rnn.cell_list.0.norm_out_h.bn_DHF1K.weight', 'rnn.cell_list.0.norm_out_h.bn_DHF1K.bias', 'rnn.cell_list.0.norm_out_h.bn_DHF1K.running_mean', 'rnn.cell_list.0.norm_out_h.bn_DHF1K.running_var', 'rnn.cell_list.0.norm_out_h.bn_DHF1K.num_batches_tracked', 'rnn.cell_list.0.norm_out_h.bn_Hollywood.weight', 'rnn.cell_list.0.norm_out_h.bn_Hollywood.bias', 'rnn.cell_list.0.norm_out_h.bn_Hollywood.running_mean', 'rnn.cell_list.0.norm_out_h.bn_Hollywood.running_var', 'rnn.cell_list.0.norm_out_h.bn_Hollywood.num_batches_tracked', 'rnn.cell_list.0.norm_out_h.bn_UCFSports.weight', 'rnn.cell_list.0.norm_out_h.bn_UCFSports.bias', 'rnn.cell_list.0.norm_out_h.bn_UCFSports.running_mean', 'rnn.cell_list.0.norm_out_h.bn_UCFSports.running_var', 'rnn.cell_list.0.norm_out_h.bn_UCFSports.num_batches_tracked', 'rnn.cell_list.0.norm_out_h.bn_SALICON.weight', 'rnn.cell_list.0.norm_out_h.bn_SALICON.bias', 'rnn.cell_list.0.norm_out_h.bn_SALICON.running_mean', 'rnn.cell_list.0.norm_out_h.bn_SALICON.running_var', 'rnn.cell_list.0.norm_out_h.bn_SALICON.num_batches_tracked', 'rnn.cell_list.0.w_r.conv_dw.weight', 'rnn.cell_list.0.w_r.sep_bn.bn_DHF1K.weight', 'rnn.cell_list.0.w_r.sep_bn.bn_DHF1K.bias', 'rnn.cell_list.0.w_r.sep_bn.bn_DHF1K.running_mean', 'rnn.cell_list.0.w_r.sep_bn.bn_DHF1K.running_var', 'rnn.cell_list.0.w_r.sep_bn.bn_DHF1K.num_batches_tracked', 'rnn.cell_list.0.w_r.sep_bn.bn_Hollywood.weight', 'rnn.cell_list.0.w_r.sep_bn.bn_Hollywood.bias', 'rnn.cell_list.0.w_r.sep_bn.bn_Hollywood.running_mean', 'rnn.cell_list.0.w_r.sep_bn.bn_Hollywood.running_var', 'rnn.cell_list.0.w_r.sep_bn.bn_Hollywood.num_batches_tracked', 'rnn.cell_list.0.w_r.sep_bn.bn_UCFSports.weight', 'rnn.cell_list.0.w_r.sep_bn.bn_UCFSports.bias', 'rnn.cell_list.0.w_r.sep_bn.bn_UCFSports.running_mean', 'rnn.cell_list.0.w_r.sep_bn.bn_UCFSports.running_var', 'rnn.cell_list.0.w_r.sep_bn.bn_UCFSports.num_batches_tracked', 'rnn.cell_list.0.w_r.sep_bn.bn_SALICON.weight', 'rnn.cell_list.0.w_r.sep_bn.bn_SALICON.bias', 'rnn.cell_list.0.w_r.sep_bn.bn_SALICON.running_mean', 'rnn.cell_list.0.w_r.sep_bn.bn_SALICON.running_var', 'rnn.cell_list.0.w_r.sep_bn.bn_SALICON.num_batches_tracked', 'rnn.cell_list.0.w_r.conv_sep.weight', 'rnn.cell_list.0.u_r.conv_dw.weight', 'rnn.cell_list.0.u_r.sep_bn.bn_DHF1K.weight', 'rnn.cell_list.0.u_r.sep_bn.bn_DHF1K.bias', 'rnn.cell_list.0.u_r.sep_bn.bn_DHF1K.running_mean', 'rnn.cell_list.0.u_r.sep_bn.bn_DHF1K.running_var', 'rnn.cell_list.0.u_r.sep_bn.bn_DHF1K.num_batches_tracked', 'rnn.cell_list.0.u_r.sep_bn.bn_Hollywood.weight', 'rnn.cell_list.0.u_r.sep_bn.bn_Hollywood.bias', 'rnn.cell_list.0.u_r.sep_bn.bn_Hollywood.running_mean', 'rnn.cell_list.0.u_r.sep_bn.bn_Hollywood.running_var', 'rnn.cell_list.0.u_r.sep_bn.bn_Hollywood.num_batches_tracked', 'rnn.cell_list.0.u_r.sep_bn.bn_UCFSports.weight', 'rnn.cell_list.0.u_r.sep_bn.bn_UCFSports.bias', 'rnn.cell_list.0.u_r.sep_bn.bn_UCFSports.running_mean', 'rnn.cell_list.0.u_r.sep_bn.bn_UCFSports.running_var', 'rnn.cell_list.0.u_r.sep_bn.bn_UCFSports.num_batches_tracked', 'rnn.cell_list.0.u_r.sep_bn.bn_SALICON.weight', 'rnn.cell_list.0.u_r.sep_bn.bn_SALICON.bias', 'rnn.cell_list.0.u_r.sep_bn.bn_SALICON.running_mean', 'rnn.cell_list.0.u_r.sep_bn.bn_SALICON.running_var', 'rnn.cell_list.0.u_r.sep_bn.bn_SALICON.num_batches_tracked', 'rnn.cell_list.0.u_r.conv_sep.weight', 'rnn.cell_list.0.w_z.conv_dw.weight', 'rnn.cell_list.0.w_z.sep_bn.bn_DHF1K.weight', 'rnn.cell_list.0.w_z.sep_bn.bn_DHF1K.bias', 'rnn.cell_list.0.w_z.sep_bn.bn_DHF1K.running_mean', 'rnn.cell_list.0.w_z.sep_bn.bn_DHF1K.running_var', 'rnn.cell_list.0.w_z.sep_bn.bn_DHF1K.num_batches_tracked', 'rnn.cell_list.0.w_z.sep_bn.bn_Hollywood.weight', 'rnn.cell_list.0.w_z.sep_bn.bn_Hollywood.bias', 'rnn.cell_list.0.w_z.sep_bn.bn_Hollywood.running_mean', 'rnn.cell_list.0.w_z.sep_bn.bn_Hollywood.running_var', 'rnn.cell_list.0.w_z.sep_bn.bn_Hollywood.num_batches_tracked', 'rnn.cell_list.0.w_z.sep_bn.bn_UCFSports.weight', 'rnn.cell_list.0.w_z.sep_bn.bn_UCFSports.bias', 'rnn.cell_list.0.w_z.sep_bn.bn_UCFSports.running_mean', 'rnn.cell_list.0.w_z.sep_bn.bn_UCFSports.running_var', 'rnn.cell_list.0.w_z.sep_bn.bn_UCFSports.num_batches_tracked', 'rnn.cell_list.0.w_z.sep_bn.bn_SALICON.weight', 'rnn.cell_list.0.w_z.sep_bn.bn_SALICON.bias', 'rnn.cell_list.0.w_z.sep_bn.bn_SALICON.running_mean', 'rnn.cell_list.0.w_z.sep_bn.bn_SALICON.running_var', 'rnn.cell_list.0.w_z.sep_bn.bn_SALICON.num_batches_tracked', 'rnn.cell_list.0.w_z.conv_sep.weight', 'rnn.cell_list.0.u_z.conv_dw.weight', 'rnn.cell_list.0.u_z.sep_bn.bn_DHF1K.weight', 'rnn.cell_list.0.u_z.sep_bn.bn_DHF1K.bias', 'rnn.cell_list.0.u_z.sep_bn.bn_DHF1K.running_mean', 'rnn.cell_list.0.u_z.sep_bn.bn_DHF1K.running_var', 'rnn.cell_list.0.u_z.sep_bn.bn_DHF1K.num_batches_tracked', 'rnn.cell_list.0.u_z.sep_bn.bn_Hollywood.weight', 'rnn.cell_list.0.u_z.sep_bn.bn_Hollywood.bias', 'rnn.cell_list.0.u_z.sep_bn.bn_Hollywood.running_mean', 'rnn.cell_list.0.u_z.sep_bn.bn_Hollywood.running_var', 'rnn.cell_list.0.u_z.sep_bn.bn_Hollywood.num_batches_tracked', 'rnn.cell_list.0.u_z.sep_bn.bn_UCFSports.weight', 'rnn.cell_list.0.u_z.sep_bn.bn_UCFSports.bias', 'rnn.cell_list.0.u_z.sep_bn.bn_UCFSports.running_mean', 'rnn.cell_list.0.u_z.sep_bn.bn_UCFSports.running_var', 'rnn.cell_list.0.u_z.sep_bn.bn_UCFSports.num_batches_tracked', 'rnn.cell_list.0.u_z.sep_bn.bn_SALICON.weight', 'rnn.cell_list.0.u_z.sep_bn.bn_SALICON.bias', 'rnn.cell_list.0.u_z.sep_bn.bn_SALICON.running_mean', 'rnn.cell_list.0.u_z.sep_bn.bn_SALICON.running_var', 'rnn.cell_list.0.u_z.sep_bn.bn_SALICON.num_batches_tracked', 'rnn.cell_list.0.u_z.conv_sep.weight', 'rnn.cell_list.0.w.conv_dw.weight', 'rnn.cell_list.0.w.sep_bn.bn_DHF1K.weight', 'rnn.cell_list.0.w.sep_bn.bn_DHF1K.bias', 'rnn.cell_list.0.w.sep_bn.bn_DHF1K.running_mean', 'rnn.cell_list.0.w.sep_bn.bn_DHF1K.running_var', 'rnn.cell_list.0.w.sep_bn.bn_DHF1K.num_batches_tracked', 'rnn.cell_list.0.w.sep_bn.bn_Hollywood.weight', 'rnn.cell_list.0.w.sep_bn.bn_Hollywood.bias', 'rnn.cell_list.0.w.sep_bn.bn_Hollywood.running_mean', 'rnn.cell_list.0.w.sep_bn.bn_Hollywood.running_var', 'rnn.cell_list.0.w.sep_bn.bn_Hollywood.num_batches_tracked', 'rnn.cell_list.0.w.sep_bn.bn_UCFSports.weight', 'rnn.cell_list.0.w.sep_bn.bn_UCFSports.bias', 'rnn.cell_list.0.w.sep_bn.bn_UCFSports.running_mean', 'rnn.cell_list.0.w.sep_bn.bn_UCFSports.running_var', 'rnn.cell_list.0.w.sep_bn.bn_UCFSports.num_batches_tracked', 'rnn.cell_list.0.w.sep_bn.bn_SALICON.weight', 'rnn.cell_list.0.w.sep_bn.bn_SALICON.bias', 'rnn.cell_list.0.w.sep_bn.bn_SALICON.running_mean', 'rnn.cell_list.0.w.sep_bn.bn_SALICON.running_var', 'rnn.cell_list.0.w.sep_bn.bn_SALICON.num_batches_tracked', 'rnn.cell_list.0.w.conv_sep.weight', 'rnn.cell_list.0.u.conv_dw.weight', 'rnn.cell_list.0.u.sep_bn.bn_DHF1K.weight', 'rnn.cell_list.0.u.sep_bn.bn_DHF1K.bias', 'rnn.cell_list.0.u.sep_bn.bn_DHF1K.running_mean', 'rnn.cell_list.0.u.sep_bn.bn_DHF1K.running_var', 'rnn.cell_list.0.u.sep_bn.bn_DHF1K.num_batches_tracked', 'rnn.cell_list.0.u.sep_bn.bn_Hollywood.weight', 'rnn.cell_list.0.u.sep_bn.bn_Hollywood.bias', 'rnn.cell_list.0.u.sep_bn.bn_Hollywood.running_mean', 'rnn.cell_list.0.u.sep_bn.bn_Hollywood.running_var', 'rnn.cell_list.0.u.sep_bn.bn_Hollywood.num_batches_tracked', 'rnn.cell_list.0.u.sep_bn.bn_UCFSports.weight', 'rnn.cell_list.0.u.sep_bn.bn_UCFSports.bias', 'rnn.cell_list.0.u.sep_bn.bn_UCFSports.running_mean', 'rnn.cell_list.0.u.sep_bn.bn_UCFSports.running_var', 'rnn.cell_list.0.u.sep_bn.bn_UCFSports.num_batches_tracked', 'rnn.cell_list.0.u.sep_bn.bn_SALICON.weight', 'rnn.cell_list.0.u.sep_bn.bn_SALICON.bias', 'rnn.cell_list.0.u.sep_bn.bn_SALICON.running_mean', 'rnn.cell_list.0.u.sep_bn.bn_SALICON.running_var', 'rnn.cell_list.0.u.sep_bn.bn_SALICON.num_batches_tracked', 'rnn.cell_list.0.u.conv_sep.weight', 'post_rnn.0.weight', 'post_rnn.1.bn_DHF1K.weight', 'post_rnn.1.bn_DHF1K.bias', 'post_rnn.1.bn_DHF1K.running_mean', 'post_rnn.1.bn_DHF1K.running_var', 'post_rnn.1.bn_DHF1K.num_batches_tracked', 'post_rnn.1.bn_Hollywood.weight', 'post_rnn.1.bn_Hollywood.bias', 'post_rnn.1.bn_Hollywood.running_mean', 'post_rnn.1.bn_Hollywood.running_var', 'post_rnn.1.bn_Hollywood.num_batches_tracked', 'post_rnn.1.bn_UCFSports.weight', 'post_rnn.1.bn_UCFSports.bias', 'post_rnn.1.bn_UCFSports.running_mean', 'post_rnn.1.bn_UCFSports.running_var', 'post_rnn.1.bn_UCFSports.num_batches_tracked', 'post_rnn.1.bn_SALICON.weight', 'post_rnn.1.bn_SALICON.bias', 'post_rnn.1.bn_SALICON.running_mean', 'post_rnn.1.bn_SALICON.running_var', 'post_rnn.1.bn_SALICON.num_batches_tracked', 'skip_2x.expansion.0.weight', 'skip_2x.expansion.1.bn_DHF1K.weight', 'skip_2x.expansion.1.bn_DHF1K.bias', 'skip_2x.expansion.1.bn_DHF1K.running_mean', 'skip_2x.expansion.1.bn_DHF1K.running_var', 'skip_2x.expansion.1.bn_DHF1K.num_batches_tracked', 'skip_2x.expansion.1.bn_Hollywood.weight', 'skip_2x.expansion.1.bn_Hollywood.bias', 'skip_2x.expansion.1.bn_Hollywood.running_mean', 'skip_2x.expansion.1.bn_Hollywood.running_var', 'skip_2x.expansion.1.bn_Hollywood.num_batches_tracked', 'skip_2x.expansion.1.bn_UCFSports.weight', 'skip_2x.expansion.1.bn_UCFSports.bias', 'skip_2x.expansion.1.bn_UCFSports.running_mean', 'skip_2x.expansion.1.bn_UCFSports.running_var', 'skip_2x.expansion.1.bn_UCFSports.num_batches_tracked', 'skip_2x.expansion.1.bn_SALICON.weight', 'skip_2x.expansion.1.bn_SALICON.bias', 'skip_2x.expansion.1.bn_SALICON.running_mean', 'skip_2x.expansion.1.bn_SALICON.running_var', 'skip_2x.expansion.1.bn_SALICON.num_batches_tracked', 'skip_2x.reduction.0.weight', 'skip_2x.reduction.0.bias', 'skip_2x.reduction.1.bn_DHF1K.weight', 'skip_2x.reduction.1.bn_DHF1K.bias', 'skip_2x.reduction.1.bn_DHF1K.running_mean', 'skip_2x.reduction.1.bn_DHF1K.running_var', 'skip_2x.reduction.1.bn_DHF1K.num_batches_tracked', 'skip_2x.reduction.1.bn_Hollywood.weight', 'skip_2x.reduction.1.bn_Hollywood.bias', 'skip_2x.reduction.1.bn_Hollywood.running_mean', 'skip_2x.reduction.1.bn_Hollywood.running_var', 'skip_2x.reduction.1.bn_Hollywood.num_batches_tracked', 'skip_2x.reduction.1.bn_UCFSports.weight', 'skip_2x.reduction.1.bn_UCFSports.bias', 'skip_2x.reduction.1.bn_UCFSports.running_mean', 'skip_2x.reduction.1.bn_UCFSports.running_var', 'skip_2x.reduction.1.bn_UCFSports.num_batches_tracked', 'skip_2x.reduction.1.bn_SALICON.weight', 'skip_2x.reduction.1.bn_SALICON.bias', 'skip_2x.reduction.1.bn_SALICON.running_mean', 'skip_2x.reduction.1.bn_SALICON.running_var', 'skip_2x.reduction.1.bn_SALICON.num_batches_tracked', 'upsampling_2.inv_res.conv.0.weight', 'upsampling_2.inv_res.conv.1.bn_DHF1K.weight', 'upsampling_2.inv_res.conv.1.bn_DHF1K.bias', 'upsampling_2.inv_res.conv.1.bn_DHF1K.running_mean', 'upsampling_2.inv_res.conv.1.bn_DHF1K.running_var', 'upsampling_2.inv_res.conv.1.bn_DHF1K.num_batches_tracked', 'upsampling_2.inv_res.conv.1.bn_Hollywood.weight', 'upsampling_2.inv_res.conv.1.bn_Hollywood.bias', 'upsampling_2.inv_res.conv.1.bn_Hollywood.running_mean', 'upsampling_2.inv_res.conv.1.bn_Hollywood.running_var', 'upsampling_2.inv_res.conv.1.bn_Hollywood.num_batches_tracked', 'upsampling_2.inv_res.conv.1.bn_UCFSports.weight', 'upsampling_2.inv_res.conv.1.bn_UCFSports.bias', 'upsampling_2.inv_res.conv.1.bn_UCFSports.running_mean', 'upsampling_2.inv_res.conv.1.bn_UCFSports.running_var', 'upsampling_2.inv_res.conv.1.bn_UCFSports.num_batches_tracked', 'upsampling_2.inv_res.conv.1.bn_SALICON.weight', 'upsampling_2.inv_res.conv.1.bn_SALICON.bias', 'upsampling_2.inv_res.conv.1.bn_SALICON.running_mean', 'upsampling_2.inv_res.conv.1.bn_SALICON.running_var', 'upsampling_2.inv_res.conv.1.bn_SALICON.num_batches_tracked', 'upsampling_2.inv_res.conv.3.weight', 'upsampling_2.inv_res.conv.4.bn_DHF1K.weight', 'upsampling_2.inv_res.conv.4.bn_DHF1K.bias', 'upsampling_2.inv_res.conv.4.bn_DHF1K.running_mean', 'upsampling_2.inv_res.conv.4.bn_DHF1K.running_var', 'upsampling_2.inv_res.conv.4.bn_DHF1K.num_batches_tracked', 'upsampling_2.inv_res.conv.4.bn_Hollywood.weight', 'upsampling_2.inv_res.conv.4.bn_Hollywood.bias', 'upsampling_2.inv_res.conv.4.bn_Hollywood.running_mean', 'upsampling_2.inv_res.conv.4.bn_Hollywood.running_var', 'upsampling_2.inv_res.conv.4.bn_Hollywood.num_batches_tracked', 'upsampling_2.inv_res.conv.4.bn_UCFSports.weight', 'upsampling_2.inv_res.conv.4.bn_UCFSports.bias', 'upsampling_2.inv_res.conv.4.bn_UCFSports.running_mean', 'upsampling_2.inv_res.conv.4.bn_UCFSports.running_var', 'upsampling_2.inv_res.conv.4.bn_UCFSports.num_batches_tracked', 'upsampling_2.inv_res.conv.4.bn_SALICON.weight', 'upsampling_2.inv_res.conv.4.bn_SALICON.bias', 'upsampling_2.inv_res.conv.4.bn_SALICON.running_mean', 'upsampling_2.inv_res.conv.4.bn_SALICON.running_var', 'upsampling_2.inv_res.conv.4.bn_SALICON.num_batches_tracked', 'upsampling_2.inv_res.conv.6.weight', 'upsampling_2.inv_res.conv.7.bn_DHF1K.weight', 'upsampling_2.inv_res.conv.7.bn_DHF1K.bias', 'upsampling_2.inv_res.conv.7.bn_DHF1K.running_mean', 'upsampling_2.inv_res.conv.7.bn_DHF1K.running_var', 'upsampling_2.inv_res.conv.7.bn_DHF1K.num_batches_tracked', 'upsampling_2.inv_res.conv.7.bn_Hollywood.weight', 'upsampling_2.inv_res.conv.7.bn_Hollywood.bias', 'upsampling_2.inv_res.conv.7.bn_Hollywood.running_mean', 'upsampling_2.inv_res.conv.7.bn_Hollywood.running_var', 'upsampling_2.inv_res.conv.7.bn_Hollywood.num_batches_tracked', 'upsampling_2.inv_res.conv.7.bn_UCFSports.weight', 'upsampling_2.inv_res.conv.7.bn_UCFSports.bias', 'upsampling_2.inv_res.conv.7.bn_UCFSports.running_mean', 'upsampling_2.inv_res.conv.7.bn_UCFSports.running_var', 'upsampling_2.inv_res.conv.7.bn_UCFSports.num_batches_tracked', 'upsampling_2.inv_res.conv.7.bn_SALICON.weight', 'upsampling_2.inv_res.conv.7.bn_SALICON.bias', 'upsampling_2.inv_res.conv.7.bn_SALICON.running_mean', 'upsampling_2.inv_res.conv.7.bn_SALICON.running_var', 'upsampling_2.inv_res.conv.7.bn_SALICON.num_batches_tracked', 'skip_4x.expansion.0.weight', 'skip_4x.expansion.1.bn_DHF1K.weight', 'skip_4x.expansion.1.bn_DHF1K.bias', 'skip_4x.expansion.1.bn_DHF1K.running_mean', 'skip_4x.expansion.1.bn_DHF1K.running_var', 'skip_4x.expansion.1.bn_DHF1K.num_batches_tracked', 'skip_4x.expansion.1.bn_Hollywood.weight', 'skip_4x.expansion.1.bn_Hollywood.bias', 'skip_4x.expansion.1.bn_Hollywood.running_mean', 'skip_4x.expansion.1.bn_Hollywood.running_var', 'skip_4x.expansion.1.bn_Hollywood.num_batches_tracked', 'skip_4x.expansion.1.bn_UCFSports.weight', 'skip_4x.expansion.1.bn_UCFSports.bias', 'skip_4x.expansion.1.bn_UCFSports.running_mean', 'skip_4x.expansion.1.bn_UCFSports.running_var', 'skip_4x.expansion.1.bn_UCFSports.num_batches_tracked', 'skip_4x.expansion.1.bn_SALICON.weight', 'skip_4x.expansion.1.bn_SALICON.bias', 'skip_4x.expansion.1.bn_SALICON.running_mean', 'skip_4x.expansion.1.bn_SALICON.running_var', 'skip_4x.expansion.1.bn_SALICON.num_batches_tracked', 'skip_4x.reduction.0.weight', 'skip_4x.reduction.0.bias', 'skip_4x.reduction.1.bn_DHF1K.weight', 'skip_4x.reduction.1.bn_DHF1K.bias', 'skip_4x.reduction.1.bn_DHF1K.running_mean', 'skip_4x.reduction.1.bn_DHF1K.running_var', 'skip_4x.reduction.1.bn_DHF1K.num_batches_tracked', 'skip_4x.reduction.1.bn_Hollywood.weight', 'skip_4x.reduction.1.bn_Hollywood.bias', 'skip_4x.reduction.1.bn_Hollywood.running_mean', 'skip_4x.reduction.1.bn_Hollywood.running_var', 'skip_4x.reduction.1.bn_Hollywood.num_batches_tracked', 'skip_4x.reduction.1.bn_UCFSports.weight', 'skip_4x.reduction.1.bn_UCFSports.bias', 'skip_4x.reduction.1.bn_UCFSports.running_mean', 'skip_4x.reduction.1.bn_UCFSports.running_var', 'skip_4x.reduction.1.bn_UCFSports.num_batches_tracked', 'skip_4x.reduction.1.bn_SALICON.weight', 'skip_4x.reduction.1.bn_SALICON.bias', 'skip_4x.reduction.1.bn_SALICON.running_mean', 'skip_4x.reduction.1.bn_SALICON.running_var', 'skip_4x.reduction.1.bn_SALICON.num_batches_tracked', 'post_upsampling_2.inv_res.conv.0.weight', 'post_upsampling_2.inv_res.conv.1.bn_DHF1K.weight', 'post_upsampling_2.inv_res.conv.1.bn_DHF1K.bias', 'post_upsampling_2.inv_res.conv.1.bn_DHF1K.running_mean', 'post_upsampling_2.inv_res.conv.1.bn_DHF1K.running_var', 'post_upsampling_2.inv_res.conv.1.bn_DHF1K.num_batches_tracked', 'post_upsampling_2.inv_res.conv.1.bn_Hollywood.weight', 'post_upsampling_2.inv_res.conv.1.bn_Hollywood.bias', 'post_upsampling_2.inv_res.conv.1.bn_Hollywood.running_mean', 'post_upsampling_2.inv_res.conv.1.bn_Hollywood.running_var', 'post_upsampling_2.inv_res.conv.1.bn_Hollywood.num_batches_tracked', 'post_upsampling_2.inv_res.conv.1.bn_UCFSports.weight', 'post_upsampling_2.inv_res.conv.1.bn_UCFSports.bias', 'post_upsampling_2.inv_res.conv.1.bn_UCFSports.running_mean', 'post_upsampling_2.inv_res.conv.1.bn_UCFSports.running_var', 'post_upsampling_2.inv_res.conv.1.bn_UCFSports.num_batches_tracked', 'post_upsampling_2.inv_res.conv.1.bn_SALICON.weight', 'post_upsampling_2.inv_res.conv.1.bn_SALICON.bias', 'post_upsampling_2.inv_res.conv.1.bn_SALICON.running_mean', 'post_upsampling_2.inv_res.conv.1.bn_SALICON.running_var', 'post_upsampling_2.inv_res.conv.1.bn_SALICON.num_batches_tracked', 'post_upsampling_2.inv_res.conv.3.weight', 'post_upsampling_2.inv_res.conv.4.bn_DHF1K.weight', 'post_upsampling_2.inv_res.conv.4.bn_DHF1K.bias', 'post_upsampling_2.inv_res.conv.4.bn_DHF1K.running_mean', 'post_upsampling_2.inv_res.conv.4.bn_DHF1K.running_var', 'post_upsampling_2.inv_res.conv.4.bn_DHF1K.num_batches_tracked', 'post_upsampling_2.inv_res.conv.4.bn_Hollywood.weight', 'post_upsampling_2.inv_res.conv.4.bn_Hollywood.bias', 'post_upsampling_2.inv_res.conv.4.bn_Hollywood.running_mean', 'post_upsampling_2.inv_res.conv.4.bn_Hollywood.running_var', 'post_upsampling_2.inv_res.conv.4.bn_Hollywood.num_batches_tracked', 'post_upsampling_2.inv_res.conv.4.bn_UCFSports.weight', 'post_upsampling_2.inv_res.conv.4.bn_UCFSports.bias', 'post_upsampling_2.inv_res.conv.4.bn_UCFSports.running_mean', 'post_upsampling_2.inv_res.conv.4.bn_UCFSports.running_var', 'post_upsampling_2.inv_res.conv.4.bn_UCFSports.num_batches_tracked', 'post_upsampling_2.inv_res.conv.4.bn_SALICON.weight', 'post_upsampling_2.inv_res.conv.4.bn_SALICON.bias', 'post_upsampling_2.inv_res.conv.4.bn_SALICON.running_mean', 'post_upsampling_2.inv_res.conv.4.bn_SALICON.running_var', 'post_upsampling_2.inv_res.conv.4.bn_SALICON.num_batches_tracked', 'post_upsampling_2.inv_res.conv.6.weight', 'post_upsampling_2.inv_res.conv.7.bn_DHF1K.weight', 'post_upsampling_2.inv_res.conv.7.bn_DHF1K.bias', 'post_upsampling_2.inv_res.conv.7.bn_DHF1K.running_mean', 'post_upsampling_2.inv_res.conv.7.bn_DHF1K.running_var', 'post_upsampling_2.inv_res.conv.7.bn_DHF1K.num_batches_tracked', 'post_upsampling_2.inv_res.conv.7.bn_Hollywood.weight', 'post_upsampling_2.inv_res.conv.7.bn_Hollywood.bias', 'post_upsampling_2.inv_res.conv.7.bn_Hollywood.running_mean', 'post_upsampling_2.inv_res.conv.7.bn_Hollywood.running_var', 'post_upsampling_2.inv_res.conv.7.bn_Hollywood.num_batches_tracked', 'post_upsampling_2.inv_res.conv.7.bn_UCFSports.weight', 'post_upsampling_2.inv_res.conv.7.bn_UCFSports.bias', 'post_upsampling_2.inv_res.conv.7.bn_UCFSports.running_mean', 'post_upsampling_2.inv_res.conv.7.bn_UCFSports.running_var', 'post_upsampling_2.inv_res.conv.7.bn_UCFSports.num_batches_tracked', 'post_upsampling_2.inv_res.conv.7.bn_SALICON.weight', 'post_upsampling_2.inv_res.conv.7.bn_SALICON.bias', 'post_upsampling_2.inv_res.conv.7.bn_SALICON.running_mean', 'post_upsampling_2.inv_res.conv.7.bn_SALICON.running_var', 'post_upsampling_2.inv_res.conv.7.bn_SALICON.num_batches_tracked', 'adaptation_dhf1k.0.weight', 'adaptation_dhf1k.0.bias', 'smoothing_dhf1k.weight', 'adaptation_hollywood.0.weight', 'adaptation_hollywood.0.bias', 'smoothing_hollywood.weight', 'adaptation_ucfsports.0.weight', 'adaptation_ucfsports.0.bias', 'smoothing_ucfsports.weight', 'adaptation_salicon.0.weight', 'adaptation_salicon.0.bias', 'smoothing_salicon.weight'])\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "print(checkpoint.keys())  # Debugging: Print available keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2881015c-e523-46a3-9b18-9b1d76a25950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(checkpoint)  # No dictionary wrapping needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c82fe6a-562d-4cc3-9935-215f339bed48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNISAL(\n",
       "  (cnn): MobileNetV2(\n",
       "    (features): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "          (3): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "          (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "          (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU6(inplace=True)\n",
       "          (6): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "          (3): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU6(inplace=True)\n",
       "          (6): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (4): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "          (3): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU6(inplace=True)\n",
       "          (6): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (5): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "          (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU6(inplace=True)\n",
       "          (6): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (6): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "          (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU6(inplace=True)\n",
       "          (6): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (7): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "          (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU6(inplace=True)\n",
       "          (6): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (8): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "          (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU6(inplace=True)\n",
       "          (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (9): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "          (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU6(inplace=True)\n",
       "          (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (10): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "          (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU6(inplace=True)\n",
       "          (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (11): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "          (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU6(inplace=True)\n",
       "          (6): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (12): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "          (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU6(inplace=True)\n",
       "          (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (13): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "          (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU6(inplace=True)\n",
       "          (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (14): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "          (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU6(inplace=True)\n",
       "          (6): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (15): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "          (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU6(inplace=True)\n",
       "          (6): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (16): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "          (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU6(inplace=True)\n",
       "          (6): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (17): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "          (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU6(inplace=True)\n",
       "          (6): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (18): Sequential(\n",
       "        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (post_cnn): Sequential(\n",
       "    (inv_res): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(1296, 1296, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1296, bias=False)\n",
       "        (1): BatchNorm2d(1296, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(1296, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (rnn): ConvGRU(\n",
       "    (cell_list): ModuleList(\n",
       "      (0): ConvGRUCell(\n",
       "        (norm_r_x): DomainBatchNorm2d(\n",
       "          (bn_DHF1K): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (bn_Hollywood): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (bn_UCFSports): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (bn_SALICON): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (norm_r_h): DomainBatchNorm2d(\n",
       "          (bn_DHF1K): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (bn_Hollywood): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (bn_UCFSports): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (bn_SALICON): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (norm_z_x): DomainBatchNorm2d(\n",
       "          (bn_DHF1K): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (bn_Hollywood): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (bn_UCFSports): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (bn_SALICON): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (norm_z_h): DomainBatchNorm2d(\n",
       "          (bn_DHF1K): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (bn_Hollywood): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (bn_UCFSports): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (bn_SALICON): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (norm_out_x): DomainBatchNorm2d(\n",
       "          (bn_DHF1K): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (bn_Hollywood): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (bn_UCFSports): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (bn_SALICON): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (norm_out_h): DomainBatchNorm2d(\n",
       "          (bn_DHF1K): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (bn_Hollywood): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (bn_UCFSports): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (bn_SALICON): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (w_r): Sequential(\n",
       "          (conv_dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "          (sep_bn): DomainBatchNorm2d(\n",
       "            (bn_DHF1K): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (bn_Hollywood): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (bn_UCFSports): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (bn_SALICON): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (sep_relu): ReLU6()\n",
       "          (conv_sep): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (u_r): Sequential(\n",
       "          (conv_dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "          (sep_bn): DomainBatchNorm2d(\n",
       "            (bn_DHF1K): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (bn_Hollywood): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (bn_UCFSports): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (bn_SALICON): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (sep_relu): ReLU6()\n",
       "          (conv_sep): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (w_z): Sequential(\n",
       "          (conv_dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "          (sep_bn): DomainBatchNorm2d(\n",
       "            (bn_DHF1K): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (bn_Hollywood): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (bn_UCFSports): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (bn_SALICON): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (sep_relu): ReLU6()\n",
       "          (conv_sep): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (u_z): Sequential(\n",
       "          (conv_dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "          (sep_bn): DomainBatchNorm2d(\n",
       "            (bn_DHF1K): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (bn_Hollywood): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (bn_UCFSports): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (bn_SALICON): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (sep_relu): ReLU6()\n",
       "          (conv_sep): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (w): Sequential(\n",
       "          (conv_dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "          (sep_bn): DomainBatchNorm2d(\n",
       "            (bn_DHF1K): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (bn_Hollywood): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (bn_UCFSports): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (bn_SALICON): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (sep_relu): ReLU6()\n",
       "          (conv_sep): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (u): Sequential(\n",
       "          (conv_dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "          (sep_bn): DomainBatchNorm2d(\n",
       "            (bn_DHF1K): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (bn_Hollywood): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (bn_UCFSports): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (bn_SALICON): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (sep_relu): ReLU6()\n",
       "          (conv_sep): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (post_rnn): Sequential(\n",
       "    (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (1): DomainBatchNorm2d(\n",
       "      (bn_DHF1K): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (bn_Hollywood): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (bn_UCFSports): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (bn_SALICON): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ReLU6(inplace=True)\n",
       "  )\n",
       "  (upsampling_1): Sequential(\n",
       "    (us1): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "    )\n",
       "  )\n",
       "  (skip_2x): Sequential(\n",
       "    (expansion): Sequential(\n",
       "      (0): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): DomainBatchNorm2d(\n",
       "        (bn_DHF1K): BatchNorm2d(320, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (bn_Hollywood): BatchNorm2d(320, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (bn_UCFSports): BatchNorm2d(320, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (bn_SALICON): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "    (dropout): Dropout2d(p=0.6, inplace=False)\n",
       "    (reduction): Sequential(\n",
       "      (0): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): DomainBatchNorm2d(\n",
       "        (bn_DHF1K): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (bn_Hollywood): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (bn_UCFSports): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (bn_SALICON): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (upsampling_2): Sequential(\n",
       "    (inv_res): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): DomainBatchNorm2d(\n",
       "          (bn_DHF1K): BatchNorm2d(768, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (bn_Hollywood): BatchNorm2d(768, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (bn_UCFSports): BatchNorm2d(768, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (bn_SALICON): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
       "        (4): DomainBatchNorm2d(\n",
       "          (bn_DHF1K): BatchNorm2d(768, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (bn_Hollywood): BatchNorm2d(768, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (bn_UCFSports): BatchNorm2d(768, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (bn_SALICON): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): DomainBatchNorm2d(\n",
       "          (bn_DHF1K): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (bn_Hollywood): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (bn_UCFSports): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (bn_SALICON): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (us2): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "    )\n",
       "  )\n",
       "  (skip_4x): Sequential(\n",
       "    (expansion): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): DomainBatchNorm2d(\n",
       "        (bn_DHF1K): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (bn_Hollywood): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (bn_UCFSports): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (bn_SALICON): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "    (dropout): Dropout2d(p=0.6, inplace=False)\n",
       "    (reduction): Sequential(\n",
       "      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): DomainBatchNorm2d(\n",
       "        (bn_DHF1K): BatchNorm2d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (bn_Hollywood): BatchNorm2d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (bn_UCFSports): BatchNorm2d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (bn_SALICON): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (post_upsampling_2): Sequential(\n",
       "    (inv_res): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): DomainBatchNorm2d(\n",
       "          (bn_DHF1K): BatchNorm2d(384, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (bn_Hollywood): BatchNorm2d(384, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (bn_UCFSports): BatchNorm2d(384, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (bn_SALICON): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "        (4): DomainBatchNorm2d(\n",
       "          (bn_DHF1K): BatchNorm2d(384, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (bn_Hollywood): BatchNorm2d(384, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (bn_UCFSports): BatchNorm2d(384, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (bn_SALICON): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): DomainBatchNorm2d(\n",
       "          (bn_DHF1K): BatchNorm2d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (bn_Hollywood): BatchNorm2d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (bn_UCFSports): BatchNorm2d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (bn_SALICON): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (adaptation_dhf1k): Sequential(\n",
       "    (0): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (smoothing_dhf1k): Conv2d(1, 1, kernel_size=(41, 41), stride=(1, 1), bias=False)\n",
       "  (adaptation_hollywood): Sequential(\n",
       "    (0): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (smoothing_hollywood): Conv2d(1, 1, kernel_size=(41, 41), stride=(1, 1), bias=False)\n",
       "  (adaptation_ucfsports): Sequential(\n",
       "    (0): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (smoothing_ucfsports): Conv2d(1, 1, kernel_size=(41, 41), stride=(1, 1), bias=False)\n",
       "  (adaptation_salicon): Sequential(\n",
       "    (0): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (smoothing_salicon): Conv2d(1, 1, kernel_size=(41, 41), stride=(1, 1), bias=False)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "40b33931-8018-4f3a-9d97-98b3820cdd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = transform(image).unsqueeze(0).to(DEVICE)  # Add batch dimension\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be703d3-0090-4695-b1bb-879e4f88d5b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d588e2-af7a-45f4-82b5-f576d3296ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b26dd6a9-d022-4a0f-822e-0ba206827449",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing 1.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 10.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 100.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 101.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 102.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 103.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 104.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 105.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 106.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 107.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 108.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 109.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 11.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 110.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 111.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 112.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 113.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 114.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 115.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 116.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 117.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 118.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 119.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 12.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 120.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 121.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 122.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 123.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 124.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 125.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 126.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 127.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 128.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 129.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 13.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 130.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 131.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 132.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 133.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 134.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 135.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 136.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 137.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 138.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 139.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 14.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 140.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 141.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 142.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 143.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 144.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 145.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 146.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 147.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 148.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 149.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 15.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 150.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 151.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 152.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 153.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 154.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 155.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 156.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 157.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 158.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 159.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 16.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 160.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 161.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 162.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 163.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 164.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 165.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 166.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 167.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 168.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 169.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 17.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 170.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 171.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 172.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 173.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 174.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 175.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 176.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 177.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 178.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 179.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 18.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 180.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 181.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 182.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 183.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 184.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 185.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 186.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 187.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 188.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 189.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 19.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 190.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 191.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 192.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 193.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 194.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 195.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 196.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 197.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 198.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 199.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 2.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 20.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 200.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 201.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 202.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 203.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 204.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 205.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 206.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 207.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 208.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 209.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 21.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 210.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 211.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 212.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 213.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 214.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 215.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 216.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 217.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 218.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 219.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 22.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 220.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 221.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 222.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 223.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 224.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 225.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 226.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 227.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 228.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 229.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 23.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 230.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 231.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 232.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 233.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 234.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 235.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 236.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 237.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 238.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 239.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 24.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 240.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 241.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 242.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 243.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 244.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 245.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 246.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 247.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 248.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 249.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 25.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 250.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 251.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 252.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 253.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 254.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 255.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 256.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 257.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 258.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 259.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 26.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 260.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 261.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 262.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 263.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 264.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 265.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 266.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 267.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 268.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 269.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 27.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 270.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 271.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 272.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 273.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 274.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 275.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 276.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 277.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 278.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 279.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 28.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 280.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 281.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 282.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 283.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 284.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 285.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 286.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 287.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 288.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 289.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 29.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 290.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 291.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 292.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 293.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 294.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 295.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 296.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 297.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 298.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 299.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 3.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 30.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 300.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 31.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 32.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 33.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 34.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 35.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 36.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 37.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 38.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 39.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 4.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 40.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 41.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 42.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 43.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 44.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 45.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 46.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 47.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 48.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 49.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 5.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 50.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 51.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 52.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 53.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 54.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 55.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 56.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 57.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 58.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 59.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 6.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 60.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 61.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 62.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 63.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 64.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 65.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 66.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 67.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 68.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 69.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 7.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 70.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 71.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 72.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 73.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 74.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 75.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 76.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 77.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 78.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 79.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 8.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 80.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 81.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 82.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 83.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 84.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 85.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 86.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 87.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 88.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 89.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 9.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 90.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 91.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 92.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 93.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 94.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 95.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 96.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 97.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 98.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n",
      "Error processing 99.png: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 1, 480, 640] to have 3 channels, but got 1 channels instead\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Paths\n",
    "image_dir = \"C:/Users/User/Downloads/Saliency4asd/Saliency4asd/Images\"\n",
    "output_dir = \"C:/Users/User/Downloads/Saliency4asd/Saliency4asd/Predicted_Unisal\"\n",
    "model_path = \"C:/Users/User/Downloads/unisal/training_runs/pretrained_unisal/weights_ft_mit1003.pth\"\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Initialize UniSAL model (without extra arguments)\n",
    "model_unisal = UNISAL().to(device)\n",
    "\n",
    "# Preprocessing function for grayscale images\n",
    "def preprocess_image(image_path):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((480, 640)),  # Resize for UniSAL\n",
    "        transforms.ToTensor(),  # Convert to tensor\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize grayscale input\n",
    "    ])\n",
    "    \n",
    "    image = Image.open(image_path).convert(\"L\")  # Ensure grayscale\n",
    "    image = transform(image).unsqueeze(0).to(device)  # Add batch dimension -> [1, 1, H, W]\n",
    "\n",
    "    return image\n",
    "\n",
    "# Function to process and save saliency maps\n",
    "def process_image(image_path, output_path):\n",
    "    image = preprocess_image(image_path)  # Preprocess grayscale image\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(image)  # Forward pass\n",
    "        if 'saliency' not in output:\n",
    "            raise KeyError(f\"ERROR: Expected 'saliency' in output, but got {output.keys()}\")\n",
    "\n",
    "        saliency_map = output['saliency'].squeeze(0).cpu().numpy()  # Extract saliency map\n",
    "\n",
    "    # Save saliency map\n",
    "    plt.imsave(output_path, saliency_map, cmap='jet')\n",
    "    print(f\"Saliency map saved: {output_path}\")\n",
    "\n",
    "# Process all images in the directory\n",
    "for image_name in os.listdir(image_dir):\n",
    "    if image_name.endswith(('.jpg', '.png')):\n",
    "        image_path = os.path.join(image_dir, image_name)\n",
    "        output_path = os.path.join(output_dir, f\"{os.path.splitext(image_name)[0]}_s.png\")\n",
    "\n",
    "        try:\n",
    "            process_image(image_path, output_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61042135-62cf-4a9b-b77d-39a1999c36dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6bfc3fed-6a88-4ea0-8315-04c186f80064",
   "metadata": {},
   "source": [
    "##try again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a8b5401f-611e-4efc-bfb9-9ea694611eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saliency prediction completed and saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define paths\n",
    "image_folder = r\"C:\\Users\\User\\Downloads\\Saliency4asd\\Saliency4asd\\Images\"\n",
    "save_folder = r\"C:\\Users\\User\\Downloads\\Saliency4asd\\Saliency4asd\\Predicted_unisal\"\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "# Define a basic UniSAL-like model (custom implementation)\n",
    "class UniSALModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UniSALModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 1, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.sigmoid(self.conv3(x))\n",
    "        return x\n",
    "\n",
    "# Initialize and load the model\n",
    "model = UniSALModel()\n",
    "model.eval()\n",
    "\n",
    "# Define image transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Process each image\n",
    "for img_name in os.listdir(image_folder):\n",
    "    img_path = os.path.join(image_folder, img_name)\n",
    "    img = Image.open(img_path).convert(\"L\")  # Keep as grayscale\n",
    "    img_tensor = transform(img).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    with torch.no_grad():\n",
    "        saliency_map = model(img_tensor)\n",
    "    \n",
    "    # Convert tensor to numpy and normalize\n",
    "    saliency_map = saliency_map.squeeze().cpu().numpy()\n",
    "    saliency_map = (saliency_map - saliency_map.min()) / (saliency_map.max() - saliency_map.min() + 1e-6)\n",
    "    saliency_map = (saliency_map * 255).astype(np.uint8)\n",
    "\n",
    "    # Save predicted saliency map with \"_s.png\" format\n",
    "    save_name = os.path.splitext(img_name)[0] + \"_s.png\"\n",
    "    save_path = os.path.join(save_folder, save_name)\n",
    "    Image.fromarray(saliency_map).save(save_path)\n",
    "\n",
    "print(\"Saliency prediction completed and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d4c77220-0f41-4431-9bcd-af8510f04cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Mean Performance Across All Images ***\n",
      "TD Fixation Map Evaluation:\n",
      "AUC_Borji: 0.5061\n",
      "AUC_Judd: 0.5061\n",
      "AUC_Shuffled: 0.5061\n",
      "CC: 0.0072\n",
      "Info_Gain: -46318.1016\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (300,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[81], line 114\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metric, values \u001b[38;5;129;01min\u001b[39;00m metrics_results_TD\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m values:  \u001b[38;5;66;03m# Avoid computing mean on empty list\u001b[39;00m\n\u001b[1;32m--> 114\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(values)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mASD Fixation Map Evaluation:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metric, values \u001b[38;5;129;01min\u001b[39;00m metrics_results_ASD\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m   3501\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3502\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m mean(axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 3504\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _methods\u001b[38;5;241m.\u001b[39m_mean(a, axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   3505\u001b[0m                       out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:102\u001b[0m, in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_mean\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 102\u001b[0m     arr \u001b[38;5;241m=\u001b[39m asanyarray(a)\n\u001b[0;32m    104\u001b[0m     is_float16_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    106\u001b[0m     rcount \u001b[38;5;241m=\u001b[39m _count_reduce_items(arr, axis, keepdims\u001b[38;5;241m=\u001b[39mkeepdims, where\u001b[38;5;241m=\u001b[39mwhere)\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (300,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.stats import entropy\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Paths to saliency maps and fixation maps\n",
    "predictions_path = r\"C:\\Users\\User\\Downloads\\Saliency4asd\\Saliency4asd\\Predicted_unisal\"\n",
    "td_fixmaps_path = r\"C:\\Users\\User\\Downloads\\Saliency4asd\\Saliency4asd\\TD_FixMaps\"\n",
    "asd_fixmaps_path = r\"C:\\Users\\User\\Downloads\\Saliency4asd\\Saliency4asd\\ASD_FixMaps\"\n",
    "\n",
    "# Get list of predicted saliency maps\n",
    "predicted_files = sorted(os.listdir(predictions_path))\n",
    "\n",
    "# Initialize dictionaries to store metric results\n",
    "metrics_results_TD = {m: [] for m in [\"AUC_Borji\", \"AUC_Judd\", \"AUC_Shuffled\", \"CC\", \"Info_Gain\", \"KL_Div\", \"NSS\"]}\n",
    "metrics_results_ASD = {m: [] for m in [\"AUC_Borji\", \"AUC_Judd\", \"AUC_Shuffled\", \"CC\", \"Info_Gain\", \"KL_Div\", \"NSS\"]}\n",
    "\n",
    "### Define Evaluation Metrics ###\n",
    "def normalize_map(saliency_map):\n",
    "    \"\"\" Normalize saliency map to sum to 1. \"\"\"\n",
    "    return saliency_map / np.sum(saliency_map)\n",
    "\n",
    "def auc_judd(saliency_map, fixation_map):\n",
    "    \"\"\" Compute AUC-Judd. \"\"\"\n",
    "    saliency = saliency_map.flatten()\n",
    "    fixations = fixation_map.flatten()\n",
    "    return roc_auc_score(fixations, saliency)\n",
    "\n",
    "def auc_borji(saliency_map, fixation_map):\n",
    "    \"\"\" Compute AUC-Borji (same as AUC-Judd in this case). \"\"\"\n",
    "    return auc_judd(saliency_map, fixation_map)\n",
    "\n",
    "def auc_shuffled(saliency_map, fixation_map):\n",
    "    \"\"\" Compute AUC-Shuffled (approximation). \"\"\"\n",
    "    return auc_judd(saliency_map, fixation_map)\n",
    "\n",
    "def correlation_coefficient(saliency_map, fixation_map):\n",
    "    \"\"\" Compute Correlation Coefficient (CC). \"\"\"\n",
    "    return np.corrcoef(saliency_map.flatten(), fixation_map.flatten())[0, 1]\n",
    "\n",
    "def kl_divergence(saliency_map, fixation_map):\n",
    "    \"\"\" Compute KL Divergence. \"\"\"\n",
    "    saliency_map = normalize_map(saliency_map)\n",
    "    fixation_map = normalize_map(fixation_map)\n",
    "    return entropy(fixation_map, saliency_map)\n",
    "\n",
    "def nss(saliency_map, fixation_map):\n",
    "    \"\"\" Compute Normalized Scanpath Saliency (NSS). \"\"\"\n",
    "    saliency_map = (saliency_map - np.mean(saliency_map)) / (np.std(saliency_map) + 1e-6)\n",
    "    return np.mean(saliency_map * fixation_map)\n",
    "\n",
    "def information_gain(saliency_map, fixation_map):\n",
    "    \"\"\" Compute Information Gain. \"\"\"\n",
    "    return np.sum(fixation_map * np.log2(saliency_map + 1e-6))\n",
    "\n",
    "### Process Each Image ###\n",
    "for filename in predicted_files:\n",
    "    # Load predicted saliency map\n",
    "    saliency_map_path = os.path.join(predictions_path, filename)\n",
    "    saliency_map = cv2.imread(saliency_map_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if saliency_map is None:\n",
    "        print(f\"Skipping {filename}: Predicted saliency map not found at {saliency_map_path}\")\n",
    "        continue\n",
    "\n",
    "    saliency_map = saliency_map.astype(np.float32) / 255.0  # Normalize\n",
    "\n",
    "    # Keep `_s.png` in filenames for correct ground truth matching\n",
    "    gt_filename = filename  # Do not modify filename\n",
    "\n",
    "    td_path = os.path.join(td_fixmaps_path, gt_filename)\n",
    "    asd_path = os.path.join(asd_fixmaps_path, gt_filename)\n",
    "\n",
    "    # Load ground truth fixation maps\n",
    "    td_fixmap = cv2.imread(td_path, cv2.IMREAD_GRAYSCALE)\n",
    "    asd_fixmap = cv2.imread(asd_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Check if ground truth fixation maps exist\n",
    "    if td_fixmap is None:\n",
    "        print(f\"Skipping {filename}: TD Fixation map not found at {td_path}\")\n",
    "        continue\n",
    "    if asd_fixmap is None:\n",
    "        print(f\"Skipping {filename}: ASD Fixation map not found at {asd_path}\")\n",
    "        continue\n",
    "\n",
    "    # Convert to binary fixation maps (1 for fixation points, 0 otherwise)\n",
    "    td_fixmap = (td_fixmap > 127).astype(np.float32)\n",
    "    asd_fixmap = (asd_fixmap > 127).astype(np.float32)\n",
    "\n",
    "    # Compute evaluation metrics for TD Fixation Map\n",
    "    metrics_results_TD[\"AUC_Borji\"].append(auc_borji(saliency_map, td_fixmap))\n",
    "    metrics_results_TD[\"AUC_Judd\"].append(auc_judd(saliency_map, td_fixmap))\n",
    "    metrics_results_TD[\"AUC_Shuffled\"].append(auc_shuffled(saliency_map, td_fixmap))\n",
    "    metrics_results_TD[\"CC\"].append(correlation_coefficient(saliency_map, td_fixmap))\n",
    "    metrics_results_TD[\"KL_Div\"].append(kl_divergence(saliency_map, td_fixmap))\n",
    "    metrics_results_TD[\"NSS\"].append(nss(saliency_map, td_fixmap))\n",
    "    metrics_results_TD[\"Info_Gain\"].append(information_gain(saliency_map, td_fixmap))\n",
    "\n",
    "    # Compute evaluation metrics for ASD Fixation Map\n",
    "    metrics_results_ASD[\"AUC_Borji\"].append(auc_borji(saliency_map, asd_fixmap))\n",
    "    metrics_results_ASD[\"AUC_Judd\"].append(auc_judd(saliency_map, asd_fixmap))\n",
    "    metrics_results_ASD[\"AUC_Shuffled\"].append(auc_shuffled(saliency_map, asd_fixmap))\n",
    "    metrics_results_ASD[\"CC\"].append(correlation_coefficient(saliency_map, asd_fixmap))\n",
    "    metrics_results_ASD[\"KL_Div\"].append(kl_divergence(saliency_map, asd_fixmap))\n",
    "    metrics_results_ASD[\"NSS\"].append(nss(saliency_map, asd_fixmap))\n",
    "    metrics_results_ASD[\"Info_Gain\"].append(information_gain(saliency_map, asd_fixmap))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "392e961d-2201-4278-80ff-423fe2caa569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Mean Performance Across All Images ***\n",
      "TD Fixation Map Evaluation:\n",
      "AUC_Borji: 0.5061\n",
      "AUC_Judd: 0.5061\n",
      "AUC_Shuffled: 0.5061\n",
      "CC: 0.0072\n",
      "Info_Gain: -46318.1016\n",
      "KL_Div: No valid data\n",
      "NSS: 0.0012\n",
      "\n",
      "ASD Fixation Map Evaluation:\n",
      "AUC_Borji: 0.4994\n",
      "AUC_Judd: 0.4994\n",
      "AUC_Shuffled: 0.4994\n",
      "CC: 0.0046\n",
      "Info_Gain: -59253.2930\n",
      "KL_Div: No valid data\n",
      "NSS: 0.0006\n"
     ]
    }
   ],
   "source": [
    "### Compute and Print Mean Performance ###\n",
    "print(\"\\n*** Mean Performance Across All Images ***\")\n",
    "\n",
    "print(\"TD Fixation Map Evaluation:\")\n",
    "for metric, values in metrics_results_TD.items():\n",
    "    numeric_values = [v for v in values if isinstance(v, (int, float, np.float32, np.float64))]  # Keep only valid numbers\n",
    "    if numeric_values:  \n",
    "        print(f\"{metric}: {np.mean(numeric_values):.4f}\")\n",
    "    else:\n",
    "        print(f\"{metric}: No valid data\")\n",
    "\n",
    "print(\"\\nASD Fixation Map Evaluation:\")\n",
    "for metric, values in metrics_results_ASD.items():\n",
    "    numeric_values = [v for v in values if isinstance(v, (int, float, np.float32, np.float64))]  # Keep only valid numbers\n",
    "    if numeric_values:\n",
    "        print(f\"{metric}: {np.mean(numeric_values):.4f}\")\n",
    "    else:\n",
    "        print(f\"{metric}: No valid data\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
