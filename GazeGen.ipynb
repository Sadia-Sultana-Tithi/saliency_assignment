{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7c35060-4b97-4db0-a9e6-d1c113c08ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Gazegan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e3ccfdd-94c9-40b1-b7bd-d75d79df817e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'Sal-CFS-GAN'...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/CZHQuality/Sal-CFS-GAN.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e9b176d-dbd6-4069-a122-9cf7cae7c17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 2] The system cannot find the file specified: 'Sal-CFS-GAN'\n",
      "C:\\Users\\User\\Sal-CFS-GAN\\Sal-CFS-GAN\n"
     ]
    }
   ],
   "source": [
    "%cd Sal-CFS-GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4fc1060-1dbe-4a49-ac55-261436da20c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\user\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\user\\anaconda3\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: pillow in c:\\users\\user\\anaconda3\\lib\\site-packages (10.4.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\anaconda3\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision numpy pillow matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1102dfc7-0b96-4e02-b3a7-cfe755a0d786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d4b07ca8-7a60-4439-94d1-47f165daadb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\User\\Downloads\\Sal-CFS-GAN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ea1336c-b1e0-46ef-bc91-d58432993691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.git', 'architecture.png', 'boundary.png', 'Figure_16_20000.png', 'Figure_16_20001.png', 'Figure_16_25000.png', 'GazeGAN_LocalGlobal_Pytorch', 'GazeGAN_using_CSC', 'mit300.jpg', 'mit300_2.jpg', 'MIT300_finetuned_on_MIT1003', 'ModelArchi11.jpg', 'My_GazeGAN_CSC.zip', 'noise2.png', 'README.md', 'Screenshot_1.jpg', 'Screenshot_10.jpg', 'Screenshot_11.jpg', 'Screenshot_12.jpg', 'Screenshot_13.jpg', 'Screenshot_14.jpg', 'Screenshot_15.jpg', 'Screenshot_16.jpg', 'Screenshot_17.jpg', 'Screenshot_18.jpg', 'Screenshot_19.jpg', 'Screenshot_2.jpg', 'Screenshot_3.jpg', 'Screenshot_4.jpg', 'Screenshot_5.jpg', 'Screenshot_6.jpg', 'Screenshot_7.jpg', 'Screenshot_8.jpg', 'Screenshot_9.jpg', 'shearing2.png', 'version1', 'versionGitHub']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir(r\"C:\\Users\\User\\Downloads\\Sal-CFS-GAN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "17083b74-f5cd-43f6-87d4-33cc390df793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['checkpointsMy', 'checkpoints_My', 'data', 'encode_features.py', 'models', 'My_data_preprocess.py', 'options', 'precompute_feature_maps.py', 'readme.md', 'run_engine.py', 'test.py', 'train.py', 'util', '_config.yml']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(r\"C:\\Users\\User\\Downloads\\Sal-CFS-GAN\\GazeGAN_LocalGlobal_Pytorch\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9943acbc-e38f-4606-9f2c-5124a5ee2bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from GazeGAN_LocalGlobal_Pytorch.models import base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f357859a-450d-482b-bac9-d1337825ad77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['base_model.py', 'models.py', 'networks.py', 'networks_old1.py', 'networks_old2.py', 'networks_old3.py', 'networks_old4.py', 'networks_old5.py', 'networks_old6.py', 'networks_ori.py', 'pix2pixHD_model.py', 'pix2pixHD_model_old1.py', 'pix2pixHD_model_old2.py', 'pix2pixHD_model_ori.py', 'readme.txt', 'ui_model.py', '__init__.py', '__pycache__']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(r\"C:\\Users\\User\\Downloads\\Sal-CFS-GAN\\GazeGAN_LocalGlobal_Pytorch\\models\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "60d12367-e0e1-4956-ae79-2a88d0425586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Path: C:/Users/User/Downloads/Saliency4asd/Saliency4asd/\n",
      "Images Directory: C:/Users/User/Downloads/Saliency4asd/Saliency4asd/Images\n",
      "TD Fixation Maps Directory: C:/Users/User/Downloads/Saliency4asd/Saliency4asd/TD_FixMaps\n",
      "ASD Fixation Maps Directory: C:/Users/User/Downloads/Saliency4asd/Saliency4asd/ASD_FixMaps\n",
      "Output Directory for Predictions: C:/Users/User/Downloads/Saliency4asd/Saliency4asd/Predicted_gazegen\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define dataset paths\n",
    "dataset_path = \"C:/Users/User/Downloads/Saliency4asd/Saliency4asd/\"\n",
    "image_folder = os.path.join(dataset_path, \"Images\")\n",
    "td_fixation_folder = os.path.join(dataset_path, \"TD_FixMaps\")\n",
    "asd_fixation_folder = os.path.join(dataset_path, \"ASD_FixMaps\")\n",
    "output_folder = os.path.join(dataset_path, \"Predicted_gazegen\")\n",
    "\n",
    "# Ensure the directories exist\n",
    "os.makedirs(image_folder, exist_ok=True)\n",
    "os.makedirs(td_fixation_folder, exist_ok=True)\n",
    "os.makedirs(asd_fixation_folder, exist_ok=True)\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "print(f\"Dataset Path: {dataset_path}\")\n",
    "print(f\"Images Directory: {image_folder}\")\n",
    "print(f\"TD Fixation Maps Directory: {td_fixation_folder}\")\n",
    "print(f\"ASD Fixation Maps Directory: {asd_fixation_folder}\")\n",
    "print(f\"Output Directory for Predictions: {output_folder}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "72602386-05d2-47fe-aed5-ee23c69e1222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 300\n",
      "Number of TD fixation maps: 300\n",
      "Number of ASD fixation maps: 300\n",
      "\n",
      "Sample files:\n",
      "Image: 1.png\n",
      "TD Fixation Map: 100_s.png\n",
      "ASD Fixation Map: 100_s.png\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "# Get list of files in each directory\n",
    "image_files = sorted(glob.glob(os.path.join(image_folder, \"*.*\")))\n",
    "td_fixation_files = sorted(glob.glob(os.path.join(td_fixation_folder, \"*.*\")))\n",
    "asd_fixation_files = sorted(glob.glob(os.path.join(asd_fixation_folder, \"*.*\")))\n",
    "\n",
    "# Check the number of files in each directory\n",
    "print(f\"Number of images: {len(image_files)}\")\n",
    "print(f\"Number of TD fixation maps: {len(td_fixation_files)}\")\n",
    "print(f\"Number of ASD fixation maps: {len(asd_fixation_files)}\")\n",
    "\n",
    "# Print sample filenames to verify the structure\n",
    "if image_files and td_fixation_files and asd_fixation_files:\n",
    "    print(\"\\nSample files:\")\n",
    "    print(f\"Image: {os.path.basename(image_files[0])}\")\n",
    "    print(f\"TD Fixation Map: {os.path.basename(td_fixation_files[0])}\")\n",
    "    print(f\"ASD Fixation Map: {os.path.basename(asd_fixation_files[0])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "012fb4be-947b-47b2-9f23-76fc24a8917f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'GazeGAN_LocalGlobal_Pytorch.models' from 'C:\\\\Users\\\\User\\\\Sal-CFS-GAN\\\\Sal-CFS-GAN\\\\GazeGAN_LocalGlobal_Pytorch\\\\models\\\\__init__.py'>\n",
      "<module 'GazeGAN_LocalGlobal_Pytorch.models.base_model' from 'C:\\\\Users\\\\User\\\\Sal-CFS-GAN\\\\Sal-CFS-GAN\\\\GazeGAN_LocalGlobal_Pytorch\\\\models\\\\base_model.py'>\n"
     ]
    }
   ],
   "source": [
    "import GazeGAN_LocalGlobal_Pytorch.models\n",
    "print(GazeGAN_LocalGlobal_Pytorch.models)\n",
    "print(base_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "39d61e96-791c-431a-857b-ab2ca5e5697c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from GazeGAN_LocalGlobal_Pytorch.models import models\n",
    "from GazeGAN_LocalGlobal_Pytorch.models import networks\n",
    "#from GazeGAN_LocalGlobal_Pytorch.options import test_options\n",
    "#from GazeGAN_LocalGlobal_Pytorch.util import Visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ae9f8d65-9a18-461a-a3bc-f5d7a70a7138",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[97], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load the pre-trained Gezegen model\u001b[39;00m\n\u001b[0;32m      5\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m base_model(pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Load Gezegen model\u001b[39;00m\n\u001b[0;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39meval()  \u001b[38;5;66;03m# Set the model to evaluation mode\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Get list of images\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "# Ensure output directory exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Load the pre-trained Gezegen model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = base_model(pretrained=True).to(device)  # Load Gezegen model\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Get list of images\n",
    "image_files = sorted(glob.glob(os.path.join(image_folder, \"*.*\")))  # Supports jpg, png, etc.\n",
    "\n",
    "# Function to preprocess image for Gezegen model\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")  # Convert to RGB\n",
    "    image = image.resize((224, 224))  # Resize for Gezegen\n",
    "    image = np.array(image).astype(np.float32) / 255.0  # Normalize\n",
    "    image = torch.tensor(image).permute(2, 0, 1).unsqueeze(0).to(device)  # Convert to tensor\n",
    "    return image\n",
    "\n",
    "# Generate and save saliency maps\n",
    "for img_path in image_files:\n",
    "    image_name = os.path.basename(img_path).split('.')[0]  # Extract image number\n",
    "    output_filename = f\"{image_name}_s.png\"  # Output format\n",
    "\n",
    "    # Preprocess the image\n",
    "    image_tensor = preprocess_image(img_path)\n",
    "\n",
    "    # Predict saliency map\n",
    "    with torch.no_grad():\n",
    "        saliency_map = model(image_tensor).cpu().numpy()[0, 0]  # Get first channel\n",
    "\n",
    "    # Normalize saliency map to 0-255\n",
    "    saliency_map = (saliency_map - saliency_map.min()) / (saliency_map.max() - saliency_map.min()) * 255\n",
    "    saliency_map = saliency_map.astype(np.uint8)\n",
    "\n",
    "    # Save saliency map\n",
    "    output_path = os.path.join(output_folder, output_filename)\n",
    "    cv2.imwrite(output_path, saliency_map)\n",
    "\n",
    "    print(f\"Saved: {output_filename}\")\n",
    "\n",
    "print(\"Saliency map generation completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9429d97d-c19b-48e8-a357-8256e4ef637e",
   "metadata": {},
   "source": [
    "### try again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8799e365-13fa-4a70-bfb8-4cfe094eca8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from scipy.stats import entropy\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0d4520e-0108-430e-b40c-ead1de7a3cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GezegenModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GezegenModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(64, 1, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.relu(self.conv4(x))\n",
    "        x = self.sigmoid(self.conv5(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1193632-d271-4b18-a076-727319a1f699",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = r\"C:\\Users\\User\\Downloads\\Saliency4asd\\Saliency4asd\\Images\"\n",
    "predictions_path = r\"C:\\Users\\User\\Downloads\\Saliency4asd\\Saliency4asd\\Predicted_Gezegen\"\n",
    "td_fixmaps_path = r\"C:\\Users\\User\\Downloads\\Saliency4asd\\Saliency4asd\\TD_FixMaps\"\n",
    "asd_fixmaps_path = r\"C:\\Users\\User\\Downloads\\Saliency4asd\\Saliency4asd\\ASD_FixMaps\"\n",
    "\n",
    "os.makedirs(predictions_path, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa742c1f-3dd9-4a03-896c-ee89631b8980",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GezegenModel()\n",
    "model.eval()\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76de3ae7-197d-4ac4-9ebf-3f66490d368a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gezegen model predictions saved.\n"
     ]
    }
   ],
   "source": [
    "for img_name in os.listdir(image_folder):\n",
    "    img_path = os.path.join(image_folder, img_name)\n",
    "    img = Image.open(img_path).convert(\"L\")  # Convert to grayscale\n",
    "    img_tensor = transform(img).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    with torch.no_grad():\n",
    "        saliency_map = model(img_tensor)\n",
    "    \n",
    "    saliency_map = saliency_map.squeeze().cpu().numpy()\n",
    "    saliency_map = (saliency_map - saliency_map.min()) / (saliency_map.max() - saliency_map.min())\n",
    "    saliency_map = (saliency_map * 255).astype(np.uint8)\n",
    "\n",
    "    # Ensure the saved filename is in {number}_s.png format\n",
    "    img_number = os.path.splitext(img_name)[0]  # Extract filename without extension\n",
    "    save_path = os.path.join(predictions_path, f\"{img_number}_s.png\")\n",
    "\n",
    "    Image.fromarray(saliency_map).save(save_path)\n",
    "\n",
    "print(\"Gezegen model predictions saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89466ffd-8700-4271-ad40-aa1bd04654af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5abeba1-2183-4a8a-bafe-423d0051b740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Mean Performance Across All Images ***\n",
      "TD Fixation Map Evaluation:\n",
      "AUC_Borji: 0.4866\n",
      "AUC_Judd: 0.4866\n",
      "AUC_Shuffled: 0.4866\n",
      "CC: -0.0012\n",
      "Info_Gain: -16969.0840\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (300,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 109\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metric, values \u001b[38;5;129;01min\u001b[39;00m metrics_results_TD\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m values:\n\u001b[1;32m--> 109\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(values)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mASD Fixation Map Evaluation:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metric, values \u001b[38;5;129;01min\u001b[39;00m metrics_results_ASD\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m   3501\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3502\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m mean(axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 3504\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _methods\u001b[38;5;241m.\u001b[39m_mean(a, axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   3505\u001b[0m                       out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:102\u001b[0m, in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_mean\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 102\u001b[0m     arr \u001b[38;5;241m=\u001b[39m asanyarray(a)\n\u001b[0;32m    104\u001b[0m     is_float16_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    106\u001b[0m     rcount \u001b[38;5;241m=\u001b[39m _count_reduce_items(arr, axis, keepdims\u001b[38;5;241m=\u001b[39mkeepdims, where\u001b[38;5;241m=\u001b[39mwhere)\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (300,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.stats import entropy\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Paths\n",
    "predictions_path = \"C:/Users/User/Downloads/Saliency4asd/Saliency4asd/Predicted_Gezegen/\"\n",
    "td_fixmaps_path = \"C:/Users/User/Downloads/Saliency4asd/Saliency4asd/TD_FixMaps/\"\n",
    "asd_fixmaps_path = \"C:/Users/User/Downloads/Saliency4asd/Saliency4asd/ASD_FixMaps/\"\n",
    "\n",
    "# Get list of predicted saliency maps\n",
    "predicted_files = sorted(os.listdir(predictions_path))\n",
    "\n",
    "# Initialize metric storage\n",
    "metrics_results_TD = {m: [] for m in [\"AUC_Borji\", \"AUC_Judd\", \"AUC_Shuffled\", \"CC\", \"Info_Gain\", \"KL_Div\", \"NSS\"]}\n",
    "metrics_results_ASD = {m: [] for m in [\"AUC_Borji\", \"AUC_Judd\", \"AUC_Shuffled\", \"CC\", \"Info_Gain\", \"KL_Div\", \"NSS\"]}\n",
    "\n",
    "### **Define Evaluation Metrics** ###\n",
    "def normalize_map(saliency_map):\n",
    "    \"\"\" Normalize saliency map to sum to 1. \"\"\"\n",
    "    return saliency_map / np.sum(saliency_map)\n",
    "\n",
    "def auc_judd(saliency_map, fixation_map):\n",
    "    \"\"\" Compute AUC-Judd. \"\"\"\n",
    "    saliency = saliency_map.flatten()\n",
    "    fixations = fixation_map.flatten()\n",
    "    return roc_auc_score(fixations, saliency)\n",
    "\n",
    "def auc_borji(saliency_map, fixation_map):\n",
    "    \"\"\" Compute AUC-Borji. \"\"\"\n",
    "    return auc_judd(saliency_map, fixation_map)\n",
    "\n",
    "def auc_shuffled(saliency_map, fixation_map):\n",
    "    \"\"\" Compute AUC-Shuffled. \"\"\"\n",
    "    return auc_judd(saliency_map, fixation_map)\n",
    "\n",
    "def correlation_coefficient(saliency_map, fixation_map):\n",
    "    \"\"\" Compute Correlation Coefficient (CC). \"\"\"\n",
    "    return np.corrcoef(saliency_map.flatten(), fixation_map.flatten())[0, 1]\n",
    "\n",
    "def kl_divergence(saliency_map, fixation_map):\n",
    "    \"\"\" Compute KL Divergence. \"\"\"\n",
    "    saliency_map = normalize_map(saliency_map)\n",
    "    fixation_map = normalize_map(fixation_map)\n",
    "    return entropy(fixation_map, saliency_map)\n",
    "\n",
    "def nss(saliency_map, fixation_map):\n",
    "    \"\"\" Compute Normalized Scanpath Saliency (NSS). \"\"\"\n",
    "    saliency_map = (saliency_map - np.mean(saliency_map)) / (np.std(saliency_map) + 1e-6)\n",
    "    return np.mean(saliency_map * fixation_map)\n",
    "\n",
    "def information_gain(saliency_map, fixation_map):\n",
    "    \"\"\" Compute Information Gain. \"\"\"\n",
    "    return np.sum(fixation_map * np.log2(saliency_map + 1e-6))\n",
    "\n",
    "### **Process Each Image** ###\n",
    "for filename in predicted_files:\n",
    "    # Load predicted saliency map\n",
    "    saliency_map = cv2.imread(os.path.join(predictions_path, filename), cv2.IMREAD_GRAYSCALE)\n",
    "    if saliency_map is None:\n",
    "        print(f\"Skipping {filename}: Predicted saliency map not found.\")\n",
    "        continue\n",
    "    saliency_map = saliency_map.astype(np.float32) / 255.0  # Normalize\n",
    "\n",
    "    # Ensure fixation maps have \"_s.png\" format (No modification required)\n",
    "    td_path = os.path.join(td_fixmaps_path, filename)\n",
    "    asd_path = os.path.join(asd_fixmaps_path, filename)\n",
    "\n",
    "    # Load fixation maps\n",
    "    td_fixmap = cv2.imread(td_path, cv2.IMREAD_GRAYSCALE)\n",
    "    asd_fixmap = cv2.imread(asd_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Check if fixation maps exist\n",
    "    if td_fixmap is None:\n",
    "        print(f\"Skipping {filename}: TD Fixation map not found at {td_path}\")\n",
    "        continue\n",
    "    if asd_fixmap is None:\n",
    "        print(f\"Skipping {filename}: ASD Fixation map not found at {asd_path}\")\n",
    "        continue\n",
    "\n",
    "    # Convert to binary fixation maps (1 for fixation points, 0 otherwise)\n",
    "    td_fixmap = (td_fixmap > 127).astype(np.float32)\n",
    "    asd_fixmap = (asd_fixmap > 127).astype(np.float32)\n",
    "\n",
    "    # Compute evaluation metrics for TD Fixation Map\n",
    "    metrics_results_TD[\"AUC_Borji\"].append(auc_borji(saliency_map, td_fixmap))\n",
    "    metrics_results_TD[\"AUC_Judd\"].append(auc_judd(saliency_map, td_fixmap))\n",
    "    metrics_results_TD[\"AUC_Shuffled\"].append(auc_shuffled(saliency_map, td_fixmap))\n",
    "    metrics_results_TD[\"CC\"].append(correlation_coefficient(saliency_map, td_fixmap))\n",
    "    metrics_results_TD[\"KL_Div\"].append(kl_divergence(saliency_map, td_fixmap))\n",
    "    metrics_results_TD[\"NSS\"].append(nss(saliency_map, td_fixmap))\n",
    "    metrics_results_TD[\"Info_Gain\"].append(information_gain(saliency_map, td_fixmap))\n",
    "\n",
    "    # Compute evaluation metrics for ASD Fixation Map\n",
    "    metrics_results_ASD[\"AUC_Borji\"].append(auc_borji(saliency_map, asd_fixmap))\n",
    "    metrics_results_ASD[\"AUC_Judd\"].append(auc_judd(saliency_map, asd_fixmap))\n",
    "    metrics_results_ASD[\"AUC_Shuffled\"].append(auc_shuffled(saliency_map, asd_fixmap))\n",
    "    metrics_results_ASD[\"CC\"].append(correlation_coefficient(saliency_map, asd_fixmap))\n",
    "    metrics_results_ASD[\"KL_Div\"].append(kl_divergence(saliency_map, asd_fixmap))\n",
    "    metrics_results_ASD[\"NSS\"].append(nss(saliency_map, asd_fixmap))\n",
    "    metrics_results_ASD[\"Info_Gain\"].append(information_gain(saliency_map, asd_fixmap))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "013bdcc5-c516-4ab5-b12c-f72e57ad95c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Mean Performance Across All Images ***\n",
      "TD Fixation Map Evaluation:\n",
      "AUC_Borji: 0.4866\n",
      "AUC_Judd: 0.4866\n",
      "AUC_Shuffled: 0.4866\n",
      "CC: -0.0012\n",
      "Info_Gain: -16969.0840\n",
      "KL_Div: No valid data\n",
      "NSS: -0.0003\n",
      "\n",
      "ASD Fixation Map Evaluation:\n",
      "AUC_Borji: 0.4832\n",
      "AUC_Judd: 0.4832\n",
      "AUC_Shuffled: 0.4832\n",
      "CC: -0.0023\n",
      "Info_Gain: -21454.3594\n",
      "KL_Div: No valid data\n",
      "NSS: -0.0007\n"
     ]
    }
   ],
   "source": [
    "### Compute and Print Mean Performance ###\n",
    "print(\"\\n*** Mean Performance Across All Images ***\")\n",
    "\n",
    "print(\"TD Fixation Map Evaluation:\")\n",
    "for metric, values in metrics_results_TD.items():\n",
    "    numeric_values = [v for v in values if isinstance(v, (int, float, np.float32, np.float64))]  # Keep only valid numbers\n",
    "    if numeric_values:  \n",
    "        print(f\"{metric}: {np.mean(numeric_values):.4f}\")\n",
    "    else:\n",
    "        print(f\"{metric}: No valid data\")\n",
    "\n",
    "print(\"\\nASD Fixation Map Evaluation:\")\n",
    "for metric, values in metrics_results_ASD.items():\n",
    "    numeric_values = [v for v in values if isinstance(v, (int, float, np.float32, np.float64))]  # Keep only valid numbers\n",
    "    if numeric_values:\n",
    "        print(f\"{metric}: {np.mean(numeric_values):.4f}\")\n",
    "    else:\n",
    "        print(f\"{metric}: No valid data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
